\newif\ifarxiv
\arxivfalse

% acmart now uses unicode-math, and mathtools needs to be loaded before it
\RequirePackage{mathtools}
\documentclass[acmsmall,screen,review,anonymous,nonacm]{acmart}
\settopmatter{printacmref=false, printccs=false, printfolios=true}

\ifarxiv
\pdfoutput=1
\nolinenumbers
\usepackage[T1]{fontenc}
\usepackage[scale=0.92]{inconsolata}
\else
\usepackage{fontspec}
\setmonofont[Scale=MatchLowercase]{inconsolata}
\fi

\usepackage[supertabular]{ottalt}
\let\newlist\relax
\let\renewlist\relax
\usepackage{thmtools} % fix cref lemma/corollary names; load BEFORE cleveref
\usepackage[capitalize,nameinlink,noabbrev]{cleveref}
\usepackage[format=plain,justification=centering]{caption}
\usepackage{enumitem,booktabs,subcaption,xspace,doi}
\usepackage{mathpartir,stmaryrd,colonequals}
\usepackage[bottom,flushmargin,multiple,para]{footmisc} % para spacing is weird and ugly

%\newcommand{\repo}{https://github.com/ionathanch/CBPV/tree/join}
\newcommand{\repo}{https://github.com/anonymous/CBPV/tree/join}
\newcommand{\thmref}[2]{\textnormal{[\texttt{\href{\repo/CBPV/#1.lean}{#1}:#2}]}}
\newcommand{\titlebreak}{\texorpdfstring{\\}{}}
\newcommand{\TODO}{\textcolor{red}{\textbf{\textsf{TODO}}}\@\xspace}
\newcommand{\ie}{\textit{i.e.}\@\xspace}
\newcommand{\eg}{\textit{e.g.}\@\xspace}
\newcommand{\etal}{\textit{et al.}\@\xspace}
\newcommand{\opcit}{\textit{op. cit.}\@\xspace}
\newcommand{\vs}{\textit{vs.}\@\xspace}
\newcommand{\ala}{\textit{\`a la}\@\xspace}
\newcommand{\apriori}{\textit{a priori}\@\xspace}
\newcommand{\aposteriori}{\textit{a posteriori}\@\xspace}
\newcommand{\fstar}{F$^\star$\@\xspace}
\newcommand{\welltyped}{well-\hspace{0pt}typed\@\xspace}
\newcommand{\wellfounded}{well-\hspace{0pt}founded\@\xspace}
\newcommand{\wellfoundedness}{well-\hspace{0pt}foundedness\@\xspace}
\newcommand{\wellformedness}{well-\hspace{0pt}formedness\@\xspace}
\newcommand{\welldefinedness}{well-\hspace{0pt}definedness\@\xspace}
\newcommand{\crude}{crude-\hspace{0pt}but-\hspace{0pt}effective\@\xspace}
\newcommand{\Acom}{tail-free computation\@\xspace}
\newcommand{\highlight}[1]{\colorbox{pink}{#1}}

\newtheorem{fail}{Falsehood}[section]
\newtheorem{prop}{Proposition}[section]

\setlength{\fboxsep}{1.5pt}
\setlength{\abovecaptionskip}{0.25\baselineskip}
\setlength{\floatsep}{\baselineskip}
\setlength{\textfloatsep}{\baselineskip}
\setlength{\intextsep}{0.25\baselineskip}
\setlength{\jot}{0\baselineskip}

\setlist[itemize]{leftmargin=2\parindent}
\setlist[enumerate]{topsep=0pt}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}

\allowdisplaybreaks
\mathtoolsset{showmanualtags}
\newtagform{brack}{[}{]}
\urlstyle{tt}

\crefformat{enumi}{#2step~#1#3}
\Crefformat{enumi}{#2step~#1#3}
\crefrangeformat{enumi}{step~#3#1#4 to #5#2#6}
\Crefrangeformat{enumi}{step~#3#1#4 to #5#2#6}
\crefformat{equation}{#2Equation~#1#3}
\Crefformat{equation}{#2Equation~#1#3}
\crefmultiformat{equation}{Equations~#2#1#3}{ and #2#1#3}{, #2#1#3}{ and #2#1#3}
\Crefmultiformat{equation}{Equations~#2#1#3}{ and #2#1#3}{, #2#1#3}{ and #2#1#3}

\citestyle{acmauthoryear}
\bibliographystyle{ACM-Reference-Format}

\title[]{Commuting Conversions and Join Points \titlebreak for Call-By-Push-Value}

\author{Jonathan Chan}
\orcid{0000-0003-0830-3180}
\affiliation{University of Pennsylvania}
\email{jcxz@seas.upenn.edu}

\author{Madi Gudin}
\affiliation{Amherst College}
\email{mgudin27@amherst.edu}

\author{Annabel Levy}
\affiliation{University of Maryland, Baltimore County}
\email{alevy2@umbc.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{University of Pennsylvania}
\email{sweirich@seas.upenn.edu}

\acmJournal{PACMPL}
\acmConference[short]{name}{date}{venue}
\acmVolume{}
\acmNumber{}
\acmArticle{}
\acmYear{}
\acmMonth{}
\acmISBN{}
\acmDOI{}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011006.10011008.10011009.10011012</concept_id>
       <concept_desc>Software and its engineering~Functional languages</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011008.10011024.10011027</concept_id>
       <concept_desc>Software and its engineering~Control structures</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Functional languages}
\ccsdesc[500]{Software and its engineering~Control structures}

\inputott{rules}

\begin{document}

\setlength{\abovedisplayskip}{0.25\baselineskip}
\setlength{\belowdisplayskip}{0.25\baselineskip}

\begin{abstract}
  \citeauthor{CBPV}'s call-by-push-value (CBPV) is a language that subsumes
  both call-by-name and call-by-value lambda calculi
  by syntactically distinguishing values from computations
  and explicitly specifying execution order.
  This low-level handling of computation suspension and resumption
  makes CBPV suitable as a compiler intermediate representation (IR),
  while its substitution evaluation semantics affords compositional reasoning about programs.
  In particular, $\beta\eta$-equivalences in CBPV have been used
  to justify compiler optimizations in low-level IRs.
  However, these equivalences do not validate \emph{commuting conversions},
  which are key transformations in compiler passes such as A-normalization.
  Such transformations syntactically rearrange computations without affecting evaluation order,
  and can reveal new opportunities for inlining.

  In this work, we identify the commuting conversions of CBPV,
  define a \emph{commuting conversion normal form} (CCNF) for CBPV,
  present a single-pass transformation into CCNF based on A-normalization,
  and prove that well-typed, translated programs evaluate to the same result.
  To avoid the usual code duplication issues that also arise with ANF,
  we adapt the explicit join point constructs by \citet{join}.
  Our results are all mechanized in Lean 4.
\end{abstract}

\maketitle

\section{Introduction}

Call-by-push-value (CBPV) \citep{CBPV} is a programming language paradigm
that syntactically distinguishes \emph{values} from \emph{computations}.
Explicit constructs between values and computations encode evaluation order
by marking where and when computations are suspended and resumed;
as a result, CBPV subsumes call-by-name (CBN) and call-by-value (CBV) evaluation strategies.
\Citeauthor{CBPV} also extends CBPV with various effects, isolating them to the computation fragment.

CBPV's distinction of pure values from effectful computations
makes it a suitable compiler intermediate representation (IR)
because it makes explicit many low-level considerations of compilers
such as closures and control flow.
Existing work covers CBPV as an IR to compile to, compile from,
and perform compiler optimizations on.

\begin{itemize}
  \item \Citet{CBPV-STAL} draws parallels between how CBPV only binds values to variables
    with pushing and popping values on the stack in stack-based typed assembly language (STAL) \citep{STAL},
    showing that they have comparable low-level features.
    He proposes adding instruction operations to CBPV,
    bringing it even closer to STAL.
  \item Explicit thunked computations in CBPV make it clear where closures ought to be created,
    and \citet{closures} add abstract closures and incremental closure conversion to CBPV
    so that optimizations involving closure conversion can be done gradually.
  \item By binding all intermediate computations,
    CBPV makes low-level control flow explicit,
    but still lends to compositional reasoning with its substitution-based evaluation semantics.
    \citet{CFG} therefore argue for using CBPV as a more compositional alternative
    to control flow graph (CFG) compiler representations by showing a tight equivalence between the two.
  \item While CFGs don't have a simple equational theory,
    \citet{equational} develop an equational theory for CBPV based on $\beta\eta$-reductions.
    They use it to trivially justify compiler optimizations,
    such as dead branch elimination and constant folding,
    which would otherwise be more difficult to justify in CFGs directly.
\end{itemize}

However, $\beta\eta$-equational theories as developed by \citet{equational} and later by \citet{CBPV-Coq}
do not validate \emph{commuting conversion} compiler transformations,
which syntactically rearrange computations without affecting their evaluation order.
\Citeauthor{CBPV-Coq} list a few commuting conversions in passing,
but they aren't comprehensive and aren't framed in the context of compilation.
Such transformations are key to compilation and
form part of well-known passes such as A-normalization \citep{ANF},
which unnest computations so that control flow is syntactically explicit,
making code easier to compile further.
Moreover, these transformations can expose new opportunities for further program inlining and simplification.
A known issue with na\"ively applying commuting conversions,
in particular in the presence of branching computations,
is that code may be duplicated;
applying many commuting conversions can then cause exponential code bloat.
\Citet{join} resolve this with explicit join point constructs.

Therefore, we look at a source-to-source transformation that applies commuting conversions to CBPV,
adapting its syntax and type system to accommodate explicit join points.
Introducing separate constructs rather than using existing ones
allows us to restrict them to only where they are needed,
which can lead to more efficient, specialized compilation later on.
In particular, because closures are represented by thunks,
adding join points to CBPV reinforces the intent that
join points represent local code blocks and should \emph{not} be compiled to closures.

This work presents a normal form for CBPV with respect to commuting conversions,
and a single-pass transformation into this normal form using join points.
We prove that this transformation is type-preserving and evaluation-preserving:
it does not change the meaning of CBPV programs.
These proofs are mechanized in Lean 4 \citep{lean}, v4.23.0-rc1.
The proof development is provided in the supplementary materials;
definitions and theorems in this paper are accompanied
by their corresponding file in the \texttt{CBPV} directory and name in the file within brackets.
In the next section, we give an overview of the language, the transformation, and its motivation,
leading to the following contributions.

\begin{itemize}
  \item We identify a subset of CBPV that is normal with respect to all commuting conversions.
    To this subset, we add join point and jump constructs,
    and design a type system enforcing non-escaping join points and tail-only jumps.
    $\hookrightarrow$~\cref{sec:cbpv}
  \item We define a single-pass transformation from CBPV into our extended normal form,
    using joins and jumps to avoid duplicating computations.
    This transformation preserves well-typedness,
    proven straightforwardly by induction.
    $\hookrightarrow$~\cref{sec:ccnf}
  \item We show that the transformation preserves evaluation behaviour:
    a closed term returning a value with no thunks
    and its transformation must return the same terminal value.
    This is proven via a logical equivalence on terms,
    and requires showing that commuting conversions are logically equivalent.
    $\hookrightarrow$~\cref{sec:proof}
\end{itemize}
%
We discuss some other program equivalences and future work in \cref{sec:discuss},
and compare with related work in \cref{sec:related}.

\section{Overview} \label{sec:overview}

The core ideas of this paper begin with the thesis that CBPV \citep{CBPV}
is suitable as a compiler IR because it represents control flow explicitly.
In particular, it subsumes both CBN and CBV semantics:
compiling the same lambda calculus term with the CBN or CBV compilation strategy yields different CBPV terms
whose execution mirrors that of the original evaluation strategy.

\begin{figure}[h]
  \begin{align}
    [[v]], [[w]] &\dblcolon= [[x]] \mid [[()]] \mid [[inl v]] \mid [[inr v]] \mid [[{m}]] \tag{values} \\
    [[m]], [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[⟨m, m⟩]] \mid [[fst n]] \mid [[snd n]] \mid [[return v]] \tag{computations} \\
    &\mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m ; inr y ⇒ m]] \nonumber
  \end{align}
  \caption{Syntax of call-by-push-value values and computations}
  \Description[]{}
  \label{fig:syntax}
\end{figure}

CBPV syntactically distinguishes values and computations, listed in \cref{fig:syntax},
using explicit thunks to turn suspended computations into values
and explicit returns to embed values into computations,
The CBN and CBV translations use thunks in different ways to enforce when computation occurs.
Alongside the thunk and return constructs,
we include the unit value, value sums, functions, and computation pairs.%
\footnote{For simplicity, we omit value pairs, which are present in Levy's original CBPV;
they are interesting in our setting because the eliminator is pattern matching,
but we already have pattern matching on value sums to consider.}
In examples to follow, we also use boolean conditionals
$\kw{if} \dots \kw{then} \dots \kw{else} \dots$
as syntactic sugar for case expressions on unit sums.

As an example of the way CBN and CBV translations differ,
consider the lambda calculus term $[[(λx. x) ((λy. y) z)]]$,
which translates to the following two CBPV terms.
%
\begin{align*}
  \textbf{CBN} &\quad [[:concrete: (λx. x!) {(λy. y!) {z!}}]] \\
  \textbf{CBV} &\quad [[:concrete: let f ← return {λx. return x} in let a ← (let g ← return {λy. return y} in g! z) in f! a]]
\end{align*}

While both terms evaluate to the same final value $[[z]]$,
their evaluation sequences are different.
In the CBN translation, function arguments are thunked ($[[{λx. return x}]]$) and passed wholesale,
then forced ($[[f!]]$) as they are needed.
In the CBV translation, the function and the argument are evaluated in order
before carrying out the function application,
using let bindings to express the explicit sequencing.
First $f$ is evaluated, followed by $g$, then $a$, before the final application occurs.

Even though translating to CBPV has made control flow explicit,
computations may still be arbitrarily nested,
while hides some compiler optimizations.
We look at commuting conversions next to handle such computations.

\subsection{Commuting conversions}

Commuting conversions are syntactic transformations
that swap nested eliminators while preserving evaluation order.
An important benefit of performing commuting conversions is that it exposes inlining opportunities ---
that is, subexpressions that can be $\beta$-reduced to simplify code.
For instance, we can commute a let-bound conditional
by pushing the outer let expression into the inner conditional
to reveal direct bindings of returned values.
%
\usetagform{brack}
\begin{align}
  \nonumber
  & [[let b ← (if v then return false else return w) in m]] \\
  \label{eq:let-if}
  \Longrightarrow \ & [[if v then (let b ← return false in m) else (let b ← return w in m)]]
\end{align}
\usetagform{default}

Now we may choose to inline $[[false]]$ inside of $[[m]]$ in place of $[[b]]$
and simplify the then branch.
We may also choose \emph{not} to inline $[[w]]$ in the else branch
if it happens that $[[w]]$ is a particularly large value we don't want to duplicate.
The inlining optimization wouldn't have been possible without the commutation,
and is a well-known technique \citep{join}.

Following \citet{join}, we define commuting conversions as all transformations
that push elimination forms inside of tail positions,
\ie the bodies of let expressions and the branches of case expressions.
\Cref{eq:let-if} pushes let bindings into conditionals;
as shown below, we can also push let bindings into other let bindings,
as well as function applications into let bindings and conditionals,
to expose those inlining opportunities.
%
\usetagform{brack}
\begin{align}
  \label{eq:let-let}
  [[let x ← (let y ← n in return v) in m]] &\Longrightarrow [[let y ← n in (let x ← return v in m)]] \\
  \label{eq:app-let}
  [[(let x ← n in λy. m) v]] &\Longrightarrow [[let x ← n in (λy. m) v]] \\
  \label{eq:app-if}
  [[(if w then (λx. m1) else (λx. m2)) v]] &\Longrightarrow [[if w then (λx. m1) v else (λx. m2) v]]
\end{align}
\usetagform{default}

Another benefit of commuting conversions is that they unnest expressions,
moving multiple steps of computation out of evaluation contexts,
which brings them closer to lower-level code.
Commuted code is easier to compile because control flow follows the shape of the syntax.
In \cref{eq:let-let}, finding the next computation to execute on the left-hand side requires
traversing into the $[[x]]$ binding, then evaluating the $[[y]]$ binding,
and finally popping back out to evaluate the body $[[m]]$.
In contrast, the right-hand side makes it explicit that we first evaluate the $[[y]]$ binding,
then the $[[x]]$ binding, then the body.

This sequential nature of commuting conversions resembles
the A-normalization compiler pass for the lambda calculus into A-normal form (ANF)
because commuting conversions are part of the A-reductions that characterize ANF \citep{ANF}.
A-normalization makes control flow syntactically explicit
by binding intermediate computations and by sequentializing computations.
Translations from the lambda calculus to CBPV already bind intermediate computations,
so what remains is to sequentialize them via commuting conversions.
Rather than performing commuting conversions one by one,
which examines the whole program each time,
we present a single-pass transformation into commuting conversion normal form (CCNF) in \cref{sec:ccnf}
that resembles the usual single-pass transformation into ANF.
%
\begin{figure}[h]
  \begin{align}
    [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[return v]] \mid [[⟨m, m⟩]] \mid [[fst n]] \mid [[snd n]] \tag{\Acom{}s} \\
    [[m]] &\dblcolon= n \mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m1 ; inr y ⇒ m2]] \tag{configurations}
  \end{align}
  \caption{Commuting conversion normal form of computations}
  \Description[]{}
  \label{fig:ccnf}
\end{figure}

In ANF, terms are divided into values, computations, and configurations,
where computations are a subset of configurations that don't include
let expressions and conditionals (or case expressions generally).
\Cref{fig:ccnf} makes the same distinction for CBPV, where values remain unchanged;
to avoid confusion, we also call the latter \emph{configurations},
while we call the former \emph{\Acom{}s},
which are both subsets of CBPV \emph{computations}.
Because commuting conversions push computations only into tail positions,
\emph{new} opportunities for inlining only occur in $[[m]]$ positions,
so performing those new inlinings won't violate CCNF.

\subsection{Join points}

Generalizing \cref{eq:let-if} to case expressions and arbitrary computations,
the corresponding commuting conversion pushes let bindings into case branches.
%
\usetagform{brack}
\begin{align}
  \nonumber
  &[[let x ← (case v of inl y1 ⇒ n1 ; inr y2 ⇒ n2) in m]] \\
  \label{eq:let-case}
  \Longrightarrow \ &[[case v of inl y1 ⇒ (let x ← n1 in m) ; inr y2 ⇒ (let x ← n1 in m)]]
\end{align}
\usetagform{default}

There is a code optimization issue with \cref{eq:let-if,eq:let-case}:
the let body $[[m]]$ gets duplicated across the branches.
If the size of $[[m]]$ is very large, this can cause code bloat,
especially if the branches contain further case expressions.
The usual solution for the lambda calculus with let expressions
is to let-bind a closure containing $[[m]]$ to be called at the end of the branch,
also known as a \emph{join point}.
Similarly, in CBPV, we can bind a thunked function to be forced and applied.
%
\usetagform{brack}
\begin{align}
  & \nonumber [[let x ← (case v of inl y1 ⇒ m1 ; inr y2 ⇒ m2) in m]] \\
  \label{eq:let-join} \Longrightarrow \ &[[let z ← return {λx. m} in _]] \\
  & \nonumber \phantom{\kw{let} \gap}
  [[case v of inl y1 ⇒ (let x ← m1 in z! x) ; inr y2 ⇒ (let x ← m2 in z! x)]]
\end{align}
\usetagform{default}

To the next compiler passes that see this code,
the thunk is a value that may capture variables and escape its scope,
so somewhere along the pipeline the thunk will be converted into a closure and lifted out,
and $[[z! x]]$ will correspond to a function call.
However, we know from the commuting conversion that the thunk will never escape its scope,
since it's never passed to a function or stored in another thunk;
all that we want to do is jump to the $[[m]]$ within and pop an argument $[[x]]$.
Its purpose is only to join up branches of a computation,
and should be compiled to a local code block.
%
\begin{figure}[h]
  \begin{align}
    m &\dblcolon= \dots \mid [[join j x = m in m]] \mid [[jump j v]]
    \tag{join points, jumps}
  \end{align}
  \caption{Extended configurations}
  \Description[]{}
  \label{fig:join}
\end{figure}

Inspired by \citet{join},
who tackle the same issue with commuting conversions in System F with case expressions,
we add explicit join point and jump constructs to CBPV in \cref{fig:join}.
They are accompanied by typing rules that restrict where join points may be used,
which we cover in \cref{sec:cbpv}.
In contrast to \opcit,
our jumps aren't \Acom{}s and may only appear in tail position,
which simplifies both the evaluation semantics and our proofs.
\Cref{sec:related} discusses why we can make this restriction.

Coming back to the commuting conversion of \cref{eq:let-join},
we use join points in place of the bound thunk,
jumping to them after binding the branches.
Let expressions only bind a single variable,
so we only need join points and jumps that take a single argument.
%
\usetagform{brack}
\begin{align}
  & \nonumber [[let x ← (case v of inl y1 ⇒ m1 ; inr y2 ⇒ m2) in m]] \\
  \Longrightarrow \ &[[join j x = m in _]] \\
  & \nonumber \phantom{\kw{join} \gap}
  [[case' v of inl y1 ⇒ (let x ← m1 in jump j x) ; inr y2 ⇒ (let x ← m2 in jump j x)]]
\end{align}
\usetagform{default}

\section{CBPV with Join Points} \label{sec:cbpv}

While \cref{sec:overview} presents the source (plain CBPV) and target (CCNF CBPV with join points)
languages with distinct syntactic forms,
in our mechanization (and thus our technical presentation here),
we use a single unified syntax and treat CC-normalization as a source-to-source translation,
showing \aposteriori in \cref{sec:ccnf} that the output of the translation satisfies \cref{fig:ccnf,fig:join}.
In \cref{sec:proof}, we reason about equivalence between a CBPV term and its translation,
which requires both sides of the equivalence to belong to the same syntactic category.

\begin{figure}[h]
  \begin{align}
    [[A]] &\dblcolon= [[⊤]] \mid [[A + A]] \mid [[U B]] \tag{value types} \\
    [[B]] &\dblcolon= [[A → B]] \mid [[B & B]] \mid [[F A]] \tag{computation types} \\
    [[v]], [[w]] &\dblcolon= [[x]] \mid [[()]] \mid [[inl v]] \mid [[inr v]] \mid [[{m}]] \tag{values} \\
    [[m]], [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[⟨m, m⟩]] \mid [[fst n]] \mid [[snd n]] \mid [[return v]] \tag{computations} \\
    &\mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m ; inr y ⇒ m]] \nonumber \\
    &\mid \highlight{$[[join j x = m in m]]$} \mid \highlight{$[[jump j v]]$} \nonumber
  \end{align}
  \caption{Syntax of value, computations, and their types \thmref{Syntax}{ValType,ComType,Val,Com}}
  \Description[]{}
  \label{fig:syntax-full}
\end{figure}

\Cref{fig:syntax-full} lists the full syntax of values and computations,
along with value types and computation types.
The new syntactic forms not found in plain CBPV are highlighted in salmon.
For clarity, although the mechanization uses de Bruijn indexing and simultaneous substitutions,
we present the syntax here in nominal form,
with \fbox{$[[v{x ↦ w}]]$}, \fbox{$[[m{x ↦ w}]]$} denoting single (capture-avoiding) substitution
of $[[x]]$ for $[[w]]$ in $[[v]]$ and $[[m]]$, respectively.
The syntax and related definitions in the mechanization are also intrinsically well scoped
with respect to jump variables, which we omit here,
and freely use jump well-scopedness throughout the proofs.

\subsection{Evaluation semantics}

The purpose of join points is best explained by what they do;
their single-step evaluation rules are listed in \cref{fig:eval},
alongside rules for the usual CBPV constructs.
We write \fbox{$[[m ⇝* m']]$} for the reflexive, transitive closure of evaluation.
The names of the rules involving join points and jumps not found in plain CBPV are highlighted in salmon.

\begin{figure}
  \setlength{\fboxsep}{3pt}
  \begin{align}
    \boxed{[[m ⇝ m]]}                        \nonumber \\
    && [[{m}! &⇝ m]]                         \tag{\ottdrulename{E-force}} \\
    && [[(λx. m) v &⇝ m{x ↦ v}]]             \tag{\ottdrulename{E-app}} \\
    && [[fst ⟨m1, m2⟩ &⇝ m1]]                \tag{\ottdrulename{E-fst}} \\
    && [[snd ⟨m1, m2⟩ &⇝ m2]]                \tag{\ottdrulename{E-snd}} \\
    && [[let x ← return v in m &⇝ m{x ↦ v}]] \tag{\ottdrulename{E-ret}} \\
    && [[case (inl v) of inl x ⇒ m1 ; inr y ⇒ m2 &⇝ m1{x ↦ v}]] \tag{\ottdrulename{E-left}} \\
    && [[case (inr v) of inl x ⇒ m1 ; inr y ⇒ m2 &⇝ m2{y ↦ v}]] \tag{\ottdrulename{E-right}} \\
    && [[join j x = m in jump j v &⇝ m{x ↦ v}]]   \tag{\highlight{\ottdrulename{E-jump}}} \\
    && [[join j' x = m' in jump j v &⇝ jump j v]] \tag{\highlight{\ottdrulename{E-skip}}} \\
    && [[join j' x = m' in tm &⇝ tm]]             \tag{\highlight{\ottdrulename{E-drop}}}
  \end{align}

  \begin{mathpar}
    \inferrule*[right=\ottdrulename{E-cong}]{[[m1 ⇝ m2]]}{[[ E[ m1 ] ⇝ E[ m2 ] ]]} \and
    \inferrule*[right=\highlight{\ottdrulename{E-join}}]{[[m1 ⇝ m2]]}{[[ join j x = m in m1 ⇝ join j x = m in m2 ]]}
  \end{mathpar}

  \begin{align}
    \textit{where} \quad
    \tag{evaluation contexts}   [[E]]  &\dblcolon= [[let x ← □ in m]] \mid [[□ v]] \mid [[fst □]] \mid [[snd □]] \\
    \tag{terminal computations} [[tm]] &\dblcolon= [[λx. m]] \mid [[return v]] \mid [[⟨m, m⟩]]
  \end{align}
  \caption{Evaluation rules for computations \thmref{Evaluation}{Eval,nf}}
  \Description[]{}
  \label{fig:eval}
\end{figure}

The usual rules \rref*{E-force} through \rref*{E-right} say that
thunks get forced to their inner computations,
applied functions substitute in their arguments,
the first and second components of a computational pair can be projected out,
and case analysis on the left or right injections
reduce to the left or right branches, respectively.
\Rref{E-cong} states that evaluation may occur under evaluation contexts $[[E]]$,
which are elimination forms with holes in scrutinee position.
We exclude join expressions from evaluation contexts
because we later use $[[E]]$ to define our set of commuting conversions,
which don't commute into join expressions.

Join expressions evaluate under a context $[[join j x = m in □]]$ in \rref{E-join}.
The inner evaluation is done when it reaches a jump or
a terminal computation $[[tm]]$, which are computation introduction forms.
If the body of the join expression is a jump to the bound join point,
then the value jumped with is substituted into the join point in \rref{E-jump}.
If it jumps to a join point further outward,
then this inner join point binding is discarded in \rref{E-skip}.
The binding is also discarded when a terminal is reached in \rref{E-drop}.

To illustrate, consider the following reduction sequence for three join points.
Intuitively, we jump to $[[j3]]$ which jumps to $[[j1]]$ which is $[[m1]]$, so we end up at $[[m1{x ↦ v}]]$;
the reductions that apply to get there are first to jump, then to skip, then to jump.
%
\begin{align}
  &[[join j1 x = m1 in join j2 x = m2 in join j3 x = jump j1 x in jump j3 v]] \nonumber \\
  &[[_ ⇝ join j1 x = m1 in join j2 x = m2 in jump j1 v]] \tag{\rref*{E-jump}} \\
  &[[_ ⇝ join j1 x = m1 in jump j1 v]] \tag{\rref*{E-skip}} \\
  &[[_ ⇝ m1{x ↦ v}]] \tag{\rref*{E-jump}}
\end{align}

This is in fact the \emph{only} sequence of reductions,
because evaluation is deterministic.
If we define normalization as evaluation to a terminal,%
\footnote{This is weak normalization, not strong normalization, since subterms are not normalized.
We won't consider strong normalization, so we simply call it normalization.}
then normalization is deterministic as well,
and multi-step evaluations always evaluate to the same terminal.

\begin{lemma}[Determinism of evaluation] \thmref{Evaluation}{Eval.det} \leavevmode \\
  If $[[m ⇝ m1]]$ and $[[m ⇝ m2]]$,
  then $[[m1]] = [[m2]]$.
\end{lemma}

\begin{definition}[Normalization] \thmref{Evaluation}{Norm} \leavevmode \\
  $[[m]]$ normalizes to $[[tm]]$,
  written as \fbox{$[[m ⇓ tm]]$},
  if $[[m ⇝* tm]]$.
\end{definition}

\begin{corollary}[Determinism of normalization] \label{lem:norm:det} \thmref{Evaluation}{Norm.join} \leavevmode \\
  If $[[m ⇓ tm1]]$ and $[[m ⇓ tm2]]$,
  then $[[tm1]] = [[tm2]]$.
\end{corollary}

\begin{corollary}[Merging] \label{lem:eval:merging} \thmref{Evaluation}{Evals.merge}
  If $[[m ⇓ tm]]$ and $[[m ⇝* m']]$,
  then $[[m' ⇓ tm]]$.
\end{corollary}

\subsection{Typing rules}

By adding join points, we now have two different forms of bindings:
value variables $[[x]]$ bind values and have value types,
while jump variables $[[j]]$ bind join points,
which are computations of type $[[B]]$ that take some value argument of type $[[A]]$.
As the bindings have different types, we use two different typing contexts:
$[[G]] \dblcolon= [[•]] \mid [[G, x : A]]$ for value contexts, and
$[[D]] \dblcolon= [[•]] \mid [[D, j : A ↗ B]]$ for jump contexts.

\begin{figure}
  \begin{mathpar}
    \fbox{$[[G ⊢ v : A]]$} \qquad \fbox{$[[G | D ⊢ m : B]]$} \hfill \\
    \inferrule[\ottdrulename{T-var}]
      {[[x : A ∈ G]]}
      %-------------%
      {[[G ⊢ x : A]]}
    \and
    \inferrule[\ottdrulename{T-unit}]{~}{[[G ⊢ () : ⊤]]}
    \and
    \inferrule[\ottdrulename{T-left}]
      {[[G ⊢ v : A1]]}
      %-----------------------%
      {[[G ⊢ inl v : A1 + A2]]}
    \and
    \inferrule[\ottdrulename{T-right}]
      {[[G ⊢ v : A2]]}
      %-----------------------%
      {[[G ⊢ inr v : A1 + A2]]}
    \and
    \inferrule[\ottdrulename{T-thunk}]
      {[[G | • ⊢ m : B]]}
      %---------------------%
      {[[G ⊢ {m} : U B]]}
    \and
    \inferrule[\ottdrulename{T-force}]
      {[[G ⊢ v : U B]]}
      %------------------%
      {[[G | D ⊢ v! : B]]}
    \and
    \inferrule[\ottdrulename{T-fun}]
      {[[G, x : A | • ⊢ m : B]]}
      %-------------------------%
      {[[G | D ⊢ λx. m : A → B]]}
    \and
    \inferrule[\ottdrulename{T-app}]
      {[[G | • ⊢ n : A → B]] \\
       [[G ⊢ v : A]]}
      %-------------------%
      {[[G | D ⊢ n v : B]]}
    \and
    \inferrule[\ottdrulename{T-ret}]
      {[[G ⊢ v : A]]}
      %--------------------------%
      {[[G | D ⊢ return v : F A]]}
    \and
    \inferrule[\ottdrulename{T-let}]
      {[[G | • ⊢ n : F A]] \\
       [[G, x : A | D ⊢ m : B]]}
      %------------------------------%
      {[[G | D ⊢ let x ← n in m : B]]}
    \and
    \inferrule[\ottdrulename{T-case}]
      {[[G ⊢ v : A1 + A2]] \\
       [[G, x : A1 | D ⊢ m1 : B]] \\
       [[G, y : A2 | D ⊢ m2 : B]]}
      %-------------------------------------------------%
      {[[G | D ⊢ case v of inl x ⇒ m1 ; inr y ⇒ m2 : B]]}
    \and
    \inferrule[\ottdrulename{T-pair}]
      {[[G | • ⊢ m1 : B1]] \\
       [[G | • ⊢ m2 : B2]]}
      %------------------------------%
      {[[G | D ⊢ ⟨m1, m2⟩ : B1 & B2]]}
    \and
    \inferrule[\ottdrulename{T-fst}]
      {[[G | • ⊢ n : B1 & B2]]}
      %----------------------%
      {[[G | D ⊢ fst n : B1]]}
    \and
    \inferrule[\ottdrulename{T-snd}]
      {[[G | • ⊢ n : B1 & B2]]}
      %----------------------%
      {[[G | D ⊢ snd n : B2]]}
    \and
    \inferrule[\highlight{\ottdrulename{T-join}}]
      {[[G, x : A | D ⊢ m1 : B]] \\
       [[G | D, j : A ↗ B ⊢ m2 : B]]}
      %-----------------------------------%
      {[[G | D ⊢ join j x = m1 in m2 : B]]}
    \and
    \inferrule[\highlight{\ottdrulename{T-jump}}]
      {[[j : A ↗ B ∈ D]] \\
       [[G ⊢ v : A]]}
      %------------------------%
      {[[G | D ⊢ jump j v : B]]}
  \end{mathpar}
  \caption{Typing rules for values and computations \thmref{Typing}{ValWt,ComWt}}
  \Description[]{}
  \label{fig:typing}
\end{figure}

Without the jump contexts, rules \rref*{T-var} through \rref*{T-snd}
are the usual typing rules for the values and computations of plain CBPV.
When we include jump contexts, they are either threaded through rules unchanged,
or they are explicitly empty in some premises.
In particular, joins represent local blocks of code that are jumped to
with the current environment, and aren't closures.
The computation inside of a thunk in \rref{T-thunk}
needs to be closed with respect to jump variables
to prevent jumps from escaping their local scopes.

Furthermore, we restrict jumps to tail positions in contrast to \citet{join},
who allow jumps in scrutinee positions.
They require type polymorphism to assign arbitrary types to jumps
so that type safety isn't violated.
We propagate the jump context only in premises with the same type
so that jumping never changes the type.
Although this restricts jumps to only tail positions,
it exactly captures what CC-normalization needs:
the ability to jump to another computation at the very end of the previous one.
As a result, the evaluation semantics are simpler
and the metatheory is cleaner.
To enforce this restriction,
the scrutinee premises of \rref{T-app,T-let,T-fst,T-snd}
require empty jump contexts,
while the tail premises of \rref{T-let,T-case} may contain jumps.

Additionally, we don't allow computation constructors \rref{T-fun,T-pair} to contain jumps,
which prevents stuck terms such as $[[fst (join j x = m in ⟨jump j v, jump j w⟩)]]$.
While the evaluation rules can be extended so that this computation reduces to $[[m{x ↦ v}]]$,
doing so again complicates both the evaluation semantics and the metatheory,
and join points for commuting conversions don't require such flexibility.

In \rref{T-join}, we extend $[[D]]$ with a join declaration when checking the body $[[m2]]$,
which may jump to the join point $[[m1]]$.
Both have the same type $[[B]]$ because jumping in tail position doesn't change the type,
and \rref{T-jump} indicates that jumping to the join point at $[[j]]$
with a value of type $[[A]]$ indeed has the same $[[B]]$.
We can then, for example, jump to a join point in only one branch of a case expression
so long as the join point has the same type as the other branch,
as in the following derivable judgement, which we typeset with a dashed bar.
%
\begin{mathpar}
  \mprset{fraction={{-~} {~-~} {~-}}}
  \infer
    {[[G ⊢ v : A1 + A2]] \\
     [[G, x : A1 | • ⊢ m1 : B]] \\
     [[G, y : A2 | • ⊢ m2 : B]]}
    %------------------------------------------------------------------------%
    {[[G | • ⊢ join j x = m1 in case v of inl x ⇒ jump j x ; inr y ⇒ m2 : B]]}
\end{mathpar}

The important typing lemmas that we need are weakening lemmas for both value and jump contexts.
In the mechanization, they are proven by induction on the typing derivation via renaming lemmas;
for now, we ignore issues of renaming de Bruijn indices, as they are standard.

\begin{lemma}[Weakening (value contexts)] \label{lem:wk:val} \thmref{Typing}{wtWeakenVal,wtWeakenCom} \leavevmode \\
  Suppose $[[x]]$ is not free in $[[v]]$, $[[m]]$.
  If $[[G1, G2 ⊢ v : A]]$, then $[[G1, x : A', G2 ⊢ v : A]]$,
  and if $[[G1, G2 | D ⊢ m : B]]$, then $[[G1, x : A, G2 | D ⊢ m : B]]$.
\end{lemma}

\begin{lemma}[Weakening (jump contexts)] \label{lem:wk:jump} \thmref{Typing}{wtWeakenJ} \leavevmode \\
  Suppose $[[j]]$ is not free in $[[m]]$.
  If $[[G | D1, D2 ⊢ m : B]]$, then $[[G | D1, j : A ↗ B', D2 ⊢ m : B]]$.

\end{lemma}

\section{Commuting Conversion Normalization} \label{sec:ccnf}

In \cref{sec:overview}, we listed four examples of commuting conversions as \crefrange{eq:let-if}{eq:app-if}.
The general formulation commutes evaluation contexts with \emph{tail contexts},
given below, which are elimination forms with holes where computations continue,
which in our case are the bodies of let expressions and the branches of case expressions.
We can think of computations with a tail as those that have a ``next step''.
As with evaluation contexts, we exclude join point expressions from tail contexts
because our source language is plain CBPV with no join points or jumps.
%
\begin{equation}
  [[L]] \dblcolon= [[let x ← n in □]] \mid [[case v of inl x ⇒ □ ; inr y ⇒ □]] \tag{tail contexts}
\end{equation}

The commuting conversions we consider can then be stated as $[[ E[ L[m] ] ]] \Rightarrow [[ L[ E[ m] ] ]]$.
Informally, they unnest code because they move evaluation contexts into the ``next step'',
and they expose inlining opportunities because these evaluation contexts are no longer
blocked by tail contexts that still have a ``first step'' to compute.
The shape of commuting conversions inform the shape of the normal form of computations,
reproduced in \cref{fig:ccnf-join}, where \Acom{}s $[[n]]$ are computations that don't contain tail contexts,
and configurations $[[m]]$ are all computations that don't contain tail contexts in scrutinee positions,
\ie where holes appear in evaluation contexts.
By inspection, CCNF is indeed normal with respect to commuting conversions because no $[[m]]$s appear in $[[n]]$s,
and therefore there must be no more commuting conversions to do.

\begin{figure}
  \begin{align}
    [[v]] &\dblcolon= [[x]] \mid [[()]] \mid [[inl v]] \mid [[inr v]] \mid [[{m}]] \tag{values} \\
    [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[return v]] \mid [[⟨m, m⟩]] \mid [[fst n]] \mid [[snd n]] \tag{\Acom{}s} \\
    [[m]] &\dblcolon= n \mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m1 ; inr y ⇒ m2]] \tag{configurations} \\
          &\mid [[join j x = m1 in m2]] \mid [[jump j v]] \nonumber
  \end{align}
  \caption{Commuting conversion normal form with join points \thmref{CCNF}{isVal,isCom,isCfg}}
  \Description[]{}
  \label{fig:ccnf-join}
\end{figure}

To transform a plain CBPV program to one in CCNF,
we follow \citet{ANF} and define a compiler using a continuation $[[K]]$,
whose forms are given below.
As usual, it can be the empty continuation $[[□]]$,
or it can be the let continuation $[[let x ← □ in m]]$:
a let expression is compiled by first translating the let-bound expression,
then binding its result to $[[x]]$, and finally continuing on with a configuration $[[m]]$.
%
\begin{align*}
  [[K]] &\dblcolon= [[□]] \mid [[let x ← □ in m]] \mid [[ K[k] ]] &
  [[k]] &\dblcolon= [[□ v]] \mid [[fst □]] \mid [[snd □]]
        &\thmref{CCNF}{K}
\end{align*}

However, we have three more continuation forms corresponding to each of the remaining three evaluation contexts:
application, first projection, and second projection.
They are needed because in contrast to ANF for the lambda calculus,
functions and computation pairs are \emph{computations} and not \emph{values},
so they can't be let-bound and their elimination forms can take arbitrary \Acom{}s.
The mutual definitions of the translation of values \fbox{$[[⟦v⟧]]$} and computations \fbox{$[[⟦m⟧ K]]$}
in \cref{fig:CC-norm} show how they are used;
we delay the translation of case expressions for the moment.

\begin{figure}[b]
  \begin{subfigure}{0.35\textwidth}
    \begin{align*}
      % \mathclap{\fbox{$[[⟦v⟧]] \coloneqq v$} \hfill} \\
      [[⟦ x ⟧]] &\coloneqq [[x]] \\
      [[⟦()⟧]] &\coloneqq [[()]] \\
      [[⟦inl v⟧]] &\coloneqq [[inl ⟦v⟧]] \\
      [[⟦inr v⟧]] &\coloneqq [[inr ⟦v⟧]] \\
      [[⟦{m}⟧]] &\coloneqq [[{⟦m⟧□}]]
    \end{align*}
    \vspace{-\baselineskip}
    \caption{Translation of values \thmref{CCNF}{CCval}}
    \label{fig:CC-norm-val}
  \end{subfigure}
  %
  \begin{subfigure}{0.55\textwidth}
    \begin{align*}
      % \mathclap{\fbox{$[[⟦m⟧ K]] \coloneqq [[n]]$} \hfill} \\
      [[⟦v!⟧ K]] &\coloneqq [[ K[⟦v⟧!] ]] \\
      [[⟦return v⟧ K]] &\coloneqq [[ K[return ⟦v⟧] ]] \\
      [[⟦λx. m⟧ K]] &\coloneqq [[ K[λx. ⟦m⟧□] ]] \\
      [[⟦⟨m1, m2⟩⟧ K]] &\coloneqq [[ K[⟨⟦m1⟧□, ⟦m2⟧□⟩] ]] \\
      [[⟦m v⟧ K]] &\coloneqq [[ ⟦m⟧ (K[□ v]) ]] \\
      [[⟦fst m⟧ K]] &\coloneqq [[ ⟦m⟧ (K[fst □]) ]] \\
      [[⟦snd m⟧ K]] &\coloneqq [[ ⟦m⟧ (K[snd □]) ]] \\
      [[⟦let x ← m1 in m2⟧ K]] &\coloneqq [[⟦m1⟧ (let x ← □ in ⟦m2⟧K)]]
    \end{align*}
    \vspace{-\baselineskip}
    \caption{Translation of computations \thmref{CCNF}{CCval}}
    \label{fig:CC-norm-com}
  \end{subfigure}

  \caption{Commuting conversion normalization translation (excluding $\kw{case}$)}
  \Description[]{}
  \label{fig:CC-norm}
\end{figure}

The translation of computations takes a continuation as a second argument,
representing the rest of the computation that expects the result of the translated computation.
The translation of values is directly recursive on the term,
with the translation of thunks being the thunk
of the translated computation using the empty continuation,
since there's no computation left to do inside the thunk.

\begin{figure}[h]
  \begin{align*}
    [[ (let x ← □ in m)[n] ]] &\coloneqq [[let x ← n in m]]
    & [[ (K[fst □])[n] ]] &\coloneqq [[ K[fst n] ]]
    & [[ □[n] ]] &\coloneqq [[n]] \\
    [[ (K[□ v])[n] ]] &\coloneqq [[ K[n v] ]]
    & [[ (K[snd □])[n] ]] &\coloneqq [[ K[snd n] ]]
  \end{align*}
  \caption{Plugging a computation in a continuation \thmref{CCNF}{plug}}
  \Description[]{}
  \label{fig:plug}
\end{figure}

To define the translation of computations,
we need a plugging operation \fbox{$[[ K[n] ]]$}
that collapses the stack of $[[k]]$s in the continuation
and replaces the final hole $[[□]]$ by the given computation $[[n]]$,
defined in \cref{fig:plug}.
Although the operation is defined over all computations,
as the holes only appear in $[[n]]$ positions,
we can only plug \Acom{}s into continuations if we want to produce a configuration.
This is the case for the translations of forcing thunks, returning values, functions, and computation pairs:
we translate their subterms---%
using empty continuations if needed, since we don't commute into introduction forms---%
and plug them directly into the continuation.
(\Cref{sec:discuss:constr} discusses why we don't commute.)

In the translation of let expressions,
the evaluation order would first compute $[[m1]]$, then $[[m2]]$,
followed by whatever computation remains in $[[K]]$.
Therefore, we translate $[[m1]]$ using a let continuation
that represents binding the result of $[[m1]]$ to $[[x]]$ then running the translation of $[[m2]]$.
For function applications and pair projections,
we translate the subterm, which we expect to yield a function or a pair,
under the continuation extended with application or projection, respectively.

To see how the translation yields CCNFs,
we can look at how they act on the left-hand side
of the commuting conversions in \cref{eq:let-let,eq:app-let},
assuming that $[[n]]$ is already in CCNF,
and using the fact that $[[⟦n⟧ K]] = [[ K[n] ]]$.
%
\begin{align}
  &  [[⟦let x ← (let y ← n in return v) in m⟧ □]]             \tag{\cref{eq:let-let}} \\
  &= [[⟦let x ← n in return v⟧ (let y ← □ in ⟦m⟧ □)]]         \tag{\textit{let}} \\
  &= [[⟦n⟧ (let x ← □ in ⟦return v⟧ (let y ← □ in ⟦m⟧ □))]]   \tag{\textit{let}} \\
  &= [[ (let x ← □ in (let y ← □ in ⟦m⟧ □)[return ⟦v⟧])[n] ]] \tag{\textit{$[[n]]$, ret}} \\
  &= [[let x ← n in (let y ← return ⟦v⟧ in ⟦m⟧ □)]]           \tag{\textit{plug}} \\
  &  [[⟦(let x ← n in λy. m) v⟧ □]]                           \tag{\cref{eq:app-let}} \\
  &= [[⟦let x ← n in λy. m⟧ (□ ⟦v⟧)]]                         \tag{\textit{app}} \\
  &= [[⟦n⟧ (let x ← □ in ⟦λy. m⟧ (□ ⟦v⟧))]]                   \tag{\textit{let}} \\
  &= [[ (let x ← □ in (□ ⟦v⟧)[λy. ⟦m⟧ □])[n] ]]               \tag{\textit{$[[n]]$, fun}} \\
  &= [[let x ← n in (λy. ⟦m⟧ □) ⟦v⟧]]                         \tag{\textit{plug}}
\end{align}

\paragraph{Branching and join points}
The na\"ive translation of conditionals duplicates the continuation:
$$[[⟦if v then m1 else m2⟧K]] = [[if ⟦v⟧ then ⟦m1⟧ K else ⟦m2⟧ K]].$$
If $[[K]]$ only contains application and projection continuations,
this is the desired translation.
From $[[fst (if v then ⟨m1, m2⟩ else n)]]$ we get $[[if v then fst ⟨m1, m2⟩ else fst n]]$,
whose true branch can then be inlined.
It doesn't make sense to jump to a join point that performs the projection,
since it would make the inlining opportunity harder to find,
and require unnecessarily thunking the computation pair to pass it to the join point.

If the continuation is $[[let x ← □ in m]]$,
duplicating it would duplicate the arbitrary configuration $[[m]]$.
In this case, we move $[[m]]$ to a join point and replace it in the continuation by a jump.
For example, from $[[let x ← (if v then return w else n) in m]]$ we get
$$[[join j x = m in (if v then (let x ← return w in jump j x) else (let x ← n in jump j x))]],$$
and the true branch can still inline the let binding.
However, we avoid creating extra join points in nested branching.
For example, from $[[let x ← (if v then n1 else (if w then n2 else n3)) in m]]$ we get
%
\begin{align*}
  &[[join j x = m in _]] \\
  &\quad [[if v then (let x ← n1 in jump j x) else _]] \\
  &\qquad [[(if w then (let x ← n2 in jump j x) else (let x ← n2 in jump j x))]],
\end{align*}
%
rather than another extraneous join point $[[j' x = jump j x]]$ in the outer false branch.

\begin{figure}
  \begin{multline*}
    [[⟦case v of inl x ⇒ m1 ; inr y ⇒ m2⟧ K]] \coloneqq \\
    \begin{cases}
      \: [[case ⟦v⟧ of inl y ⇒ ⟦m1⟧ K ; inr z ⇒ ⟦m2⟧ K]]
      &\textit{if} ~{}~ [[K]] \equiv [[ □ [k1] - [ki] ]] \\
      &\textit{or} ~{}~ [[K]] \equiv [[(let x ← □ in jump j x) [k1] - [ki] ]] \\
      \: [[join j x = m in _]] &\textit{if} ~{}~ [[K]] \equiv [[ (let x ← □ in m) [k1] - [ki] ]] \\[1.2\baselineskip]
      \: \quad [[case ⟦v⟧ of inl y ⇒ ⟦m1⟧ K' ; inr z ⇒ ⟦m2⟧ K']]
      &\textit{and} ~{}~ [[m]] \not\equiv [[jump j x]]
    \end{cases}
    \\
    \textit{where} ~{}~ [[K']] \coloneqq [[(let x ← □ in jump j x) [k1] - [ki] ]]
  \end{multline*}
  \caption{Translation of case expressions to CCNF with join points \thmref{CCNF}{CCcom,K.jumpify}}
  \Description[]{}
  \label{fig:CC-norm-case}
\end{figure}

\Cref{fig:CC-norm-case} generalizes this strategy to case expressions and nested continuations;
whether we construct a join point depends on whether the continuation ends in a let continuation
whose body isn't already a jump to a join point.
In the mechanization, this is a source-to-source translation
over CBPV terms (without join points) to CBPV terms (with join points).
We need to explicitly prove that the translation indeed produces terms in CCNF,
which holds by inspection, \ie mutual induction over the syntax.

\begin{lemma}[Plugging preserves CCNF] \thmref{CCNF}{isK.plug} \leavevmode \\
  If the subterms of $[[K]]$ are in CCNF and $[[n]]$ is in CCNF,
  then $[[ K[n] ]]$ is in CCNF.
\end{lemma}

\begin{lemma}[CCNF preservation] \label{lem:ccnf-preservation} \thmref{CCNF}{isCCNF,isK.jumpify} \leavevmode \\
  If the subterms of $[[K]]$ are in CCNF,
  then $[[⟦v⟧]]$ and $[[⟦m⟧ K]]$ are in CCNF.
\end{lemma}

\subsection{Commuting conversion preserves typing}

With \cref{lem:ccnf-preservation},
we know that the translation performs all the commuting conversions
in the directions we desire.
However, this alone doesn't guarantee that the translation preserves the \emph{meaning}
of the values and computations.
We say what we mean by meaning preservation in the next section,
whose proof uses typing preservation:
a translated term must behave like the same kind of term as the original term.

\begin{figure}[h]
  \begin{mathpar}
    \fbox{$[[G | D ⊢ K : B1 ⇒ B2]]$} \hfill \\
    \inferrule[\ottdrulename{K-let}]
      {[[G, x : A | D ⊢ m : B]]}
      %------------------------------------%
      {[[G | D ⊢ let x ← □ in m : F A ⇒ B]]}
    \and
    \inferrule[\ottdrulename{K-app}]
      {[[G ⊢ v : A]] \\
       [[G | D ⊢ K : B1 ⇒ B2]]}
      %----------------------------------%
      {[[G | D ⊢ K[□ v] : (A → B1) ⇒ B2]]}
    \and
    \inferrule[\ottdrulename{K-fst}]
      {[[G | D ⊢ K : B1 ⇒ B]]}
      %------------------------------------%
      {[[G | D ⊢ K[fst □] : (B1 & B2) ⇒ B]]}
    \quad
    \inferrule[\ottdrulename{K-snd}]
      {[[G | D ⊢ K : B1 ⇒ B]]}
      %------------------------------------%
      {[[G | D ⊢ K[snd □] : (B1 & B2) ⇒ B]]}
    \quad
    \inferrule[\ottdrulename{K-hole}]{~}
      {[[G | D ⊢ □ : B ⇒ B]]}
  \end{mathpar}
  \caption{Typing rules for continuations \thmref{CCNF}{wtK}}
  \Description[]{}
  \label{fig:typing-K}
\end{figure}

To show type preservation, we first need a typing judgement for the continuations,
given in \cref{fig:typing-K}.
A continuation $[[K]]$ having type $[[B1 ⇒ B2]]$ means that
if the hole in $[[K]]$ represents a missing computation of type $[[B1]]$,
then $[[K]]$ with its hole plugged in would be a computation of type $[[B2]]$.
Consequently, we can show that plugging preserves typing,
which is used in the proof of type preservation.
We also need an inversion lemma for continuations that end in let continuations.

\begin{lemma}[Plugging preserves typing] \label{lem:preservation:plug} \thmref{CCNF}{wtK.plug} \leavevmode \\
  If $[[G | D ⊢ K : B1 ⇒ B2]]$ and $[[G | • ⊢ n : B1]]$,
  then $[[G | D ⊢ K[n] : B2]]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[K]]$,
  using \cref{lem:wk:jump} in the \rref*{K-hole} case.
\end{proof}

\begin{lemma}[Let continuation inversion] \label{lem:k-let:inv} \thmref{CCNF}{wtK.jumpify}
  If $[[K]] = [[(let x ← □ in m)]][ [[k1]] ] \dots [ [[ki]] ]$
  and $[[G | D ⊢ K : B1 ⇒ B2]]$,
  then there exists some $[[A]]$ such that
  $[[G | D, j : A ↗ B2 ⊢ K' : B1 ⇒ B2]]$
  and $[[G, x : A | D ⊢ m : B2]]$,
  where $[[K']] = [[(let x ← □ in jump j x)]][ [[k1]] ] \dots [ [[ki]] ]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[K]]$.
\end{proof}

\begin{lemma}[Type preservation] \label{lem:preservation} \thmref{CCNF}{preservation}
  Suppose $[[v]]$ and $[[m]]$ are plain CBPV terms
  (and thus have no join points or jumps).
  If $[[G ⊢ v : A]]$, then $[[G ⊢ ⟦v⟧ : A]]$,
  and if $[[G | • ⊢ m : B1]]$ and $[[G | D ⊢ K : B1 ⇒ B2]]$,
  then $[[G | D ⊢ ⟦m⟧ K : B2]]$.
\end{lemma}

\begin{proof}
  By mutual induction on the typing derivations of $[[v]]$ and $[[m]]$,
  using \cref{lem:preservation:plug} in the \rref*{T-force,T-fun,T-pair} cases.
  In the \rref*{T-case} case,
  if $[[K]]$ is a let continuation,
  use \cref{lem:k-let:inv} and \rref{T-join} to construct the derivation.
\end{proof}

\section{Commuting Conversion Normalization Preserves Evaluation} \label{sec:proof}

Normalizing by all commuting conversions shouldn't affect the meaning of a program.
Formally, if a closed computation evaluates to a returned value,
then its translation runs to the same value.
Because we don't evaluate inside of thunks,
we consider only computations that return \emph{ground} values,
which are those of type $[[T]] \dblcolon= [[⊤]] \mid [[T + T]]$.
Otherwise, a thunk and its CCNF are values that don't evaluate any further,
but aren't necessarily syntactically equal.

\begin{theorem} \label{thm:ground-run}
  Given $[[m]]$ such that $[[• | • ⊢ m : F T]]$,
  if $[[m ⇓ return v]]$, then $[[⟦ m ⟧ □ ⇓ return v]]$.
\end{theorem}

We prove this property as a corollary of a logical equivalence between a computation and its translation.
This machinery is required because the simpler of method using a simulation argument,
such as the following statement, unfortunately doesn't work.

\begin{fail}[Simulation]
  If $[[m ⇝ n]]$ then $[[⟦m⟧ □ ⇝* ⟦n⟧ □]]$.
\end{fail}
\begin{proof}[Counterexample]
  Suppose we have \Acom{}s $[[n1]]$, $[[n2]]$ and configuration $[[m]]$.
  Consider the term $[[let x ← {let y ← n1 in n2}! in m]]$,
  which reduces to $[[let x ← (let y ← n1 in n2) in m]]$.
  The left-hand side translates to itself, since it's already in CCNF,
  while the right-hand side translates to $[[let y ← n1 in let x ← n2 in m]]$.
  By transitivity, it remains to show that
  $[[let x ← (let y ← n1 in n2) in m ⇝* let y ← n1 in let x ← n2 in m]]$,
  but there is no such reduction sequence since there is no reduction step that commutes let bindings.
\end{proof}

However, if we know that $[[n1]]$ in the counterexample reduces to some $[[return v]]$,
then we can deduce that the right side and its translation must reduce to
$[[let x ← n2{y ↦ v} in m]]$, which gives us an equivalence between the original term and its translation.
If our counterexample is well typed,
then a logical equivalence gives us precisely the required information that
subterms must reduce to canonical terms such as returned values.

To handle translations with arbitrary translation continuation $[[K]]$,
we generalize to proving that a translation $[[⟦m⟧ K]]$
must be equivalent to plugging the computation back in as $[[ K[m] ]]$.
The proof of \cref{thm:ground-run} then proceeds by:
\begin{enumerate}
  \item \label{item:logrel} Defining a standard logical equivalence over CBPV types;
  \item \label{item:semeq} Closing over term and join point contexts with a semantic equivalence;
  \item \label{item:fundamental} Proving the fundamental theorem of this equivalence,
    namely that well-typed terms are semantically equivalent to themselves;
  \item \label{item:cc} Showing that well-typed commuting conversions are in the semantic equivalence;
  \item \label{item:kont} Defining semantic equivalence of continuations
    and proving its fundamental theorem;
  \item \label{item:plug} Showing that plugging continuations respects semantic equivalence; and finally,
  \item \label{item:end} Proving that given a well-typed computation and a well-typed continuation,
    plugging the continuation with the computation
    is equivalent to translating the computation using the continuation.
\end{enumerate}
The theorem then holds by instantiating with the empty continuation.
\Cref{sec:proof:logrel} covers \crefrange{item:logrel}{item:fundamental},
\cref{sec:proof:cc} covers \cref{item:cc},
\cref{sec:proof:plug} covers \crefrange{item:kont}{item:plug},
and \cref{sec:proof:end} covers \cref{item:end}.

\subsection{Logical equivalence and the fundamental theorem} \label{sec:proof:logrel}

\begin{figure}[h]
  \begin{align*}
    \mathclap{\fbox{$[[(v, w) ∈ A]]$} \quad \fbox{$[[(m, n) ∈ B]]$} \quad \fbox{$[[(m, n) ∈* B]]$}} \hfill \\
    [[((), ()) ∈ ⊤]] & \\
    [[(inl v, inl w) ∈ A1 + A2]]       &\textit{ iff } [[(v, w) ∈ A1]] \\
    [[(inr v, inr w) ∈ A1 + A2]]       &\textit{ iff } [[(v, w) ∈ A2]] \\
    [[({m}, {n}) ∈ U B]]               &\textit{ iff } [[(m, n) ∈* B]] \\
    [[(return v, return w) ∈ F A]]     &\textit{ iff } [[(v, w) ∈ A]] \\
    [[(λx. m, λx. n) ∈ A → B]]         &\textit{ iff } \forall [[v]], [[w]] \mathpunct{.} [[(v, w) ∈ A]] ⇒ [[(m{x ↦ v}, n{x ↦ w}) ∈* B]] \\
    [[(⟨m1, m2⟩, ⟨n1, n2⟩) ∈ B1 & B2]] &\textit{ iff } [[(m1, n1) ∈* B1]] \wedge [[(m2, n2) ∈* B2]] \\
    [[(m, n) ∈* B]]                    &\textit{ iff } \exists [[tm1]], [[tm2]] \mathpunct{.} ([[m ⇓ tm1]]) \wedge ([[n ⇓ tm2]]) \wedge [[(tm1, tm2) ∈ B]]
  \end{align*}
  \caption{Logical equivalence of terms over CBPV types \thmref{Equivalence}{$\mathcal{V},\mathcal{C},\mathcal{E}$}}
  \Description[]{}
  \label{fig:logeq}
\end{figure}

Our logical relation relates two closed values or computations at a value or computation type, respectively.
We equivalently say that a pair of terms are in the interpretation of some type.
Following the presentation by \citet{CBPV-Coq},
we use an auxiliary interpretation $[[⟦B⟧*]]$ which relates computations
that normalize to terminals related at $[[B]]$.
It follows that if $[[(m, n) ∈ B]]$, then $[[(m, n) ∈* B]]$.

The interpretations, defined by mutual recursion over types, are otherwise standard:
unit values are related,
left and right injections are related when their values are related at the respective left or right type,
thunks are related when their computations are related,
functions are related when their bodies are related for all related arguments,
and pairs are related when their first and second components are respectively related.

The first property we need of logical equivalence is backward closure under evaluation of $[[⟦B⟧*]]$,
which holds by unfolding its definition and transitivity of evaluation.
A helpful corollary adds congruence under join points.

\begin{lemma}[Backward closure] \label{lem:logeq:bwds} \thmref{Equivalence}{bwds} \leavevmode \\
  If $[[m1 ⇝* m2]]$ and $[[n1 ⇝* n2]]$ and $[[(m2, n2) ∈* B]]$,
  then $[[(m1, n1) ∈* B]]$.
\end{lemma}

\begin{lemma}[Backward closure under join points] \label{lem:logeq:bwds-joins} \thmref{Equivalence}{bwdsRejoin} \leavevmode \\
  If $[[m1 ⇝* m2]]$ and $[[n1 ⇝* n2]]$ and $[[(m2, n2) ∈* B]]$,
  then $[[(join j x = m' in m1, join j x = n' in m2) ∈* B]]$,
  using \rref{E-join,E-drop}.
\end{lemma}

The second property is symmetry and transitivity,
making it a partial equivalence relation over all terms.
These lemmas are proven by induction over the type and unfolding definitions.

\begin{lemma}[Symmetry and transitivity (logical equivalence)] \label{lem:logeq:PER} \leavevmode
  \begin{itemize}
    \item If $[[(v, w) ∈ A]]$ then $[[(w, v) ∈ A]]$. \thmref{Equivalence}{$\mathcal{V}$.sym}
    \item If $[[(m, n) ∈ B]]$ then $[[(n, m) ∈ B]]$. \thmref{Equivalence}{$\mathcal{C}$.sym}
    \item If $[[(m, n) ∈* B]]$ then $[[(n, m) ∈* B]]$. \thmref{Equivalence}{$\mathcal{E}$.sym}
    \item If $[[(v1, v2) ∈ A]]$ and $[[(v2, v3) ∈ A]]$ then $[[(v1, v3) ∈ A]]$. \thmref{Equivalence}{$\mathcal{V}$.trans}
    \item If $[[(m1, m2) ∈ B]]$ and $[[(m2, m3) ∈ B]]$ then $[[(m1, m3) ∈ B]]$. \thmref{Equivalence}{$\mathcal{C}$.trans}
    \item If $[[(m1, m2) ∈* B]]$ and $[[(m2, m3) ∈* B]]$ then $[[(m1, m3) ∈* B]]$. \thmref{Equivalence}{$\mathcal{E}$.trans}
  \end{itemize}
\end{lemma}

To work with equivalence of well-typed terms,
which may be open with respect to value and jump contexts,
we need close over value and jump variables
using substitution maps $[[s]]$ and join stacks $[[p]]$,
defined below.
Applying a substitution map $[[v{s}]]$, $[[m{s}]]$
corresponds to simultaneous substitution (so order doesn't matter in $[[s]]$).
Given a join stack $[[p]] \equiv [[j1 x1 = m1]], \dots, [[ji xi = mi]]$,
the computation $[[joins p in m]]$ represents wrapping $[[m]]$ in join points outward in,
corresponding to the term $[[join j1 x1 = m1 in _]] \dots [[join ji xi = mi in m]]$
(so order \emph{does} matter in $[[p]]$).
%
\begin{align*}
  [[s]], [[t]] &\dblcolon= [[•]] \mid [[s, x ↦ v]] &
  [[p]], [[q]] &\dblcolon= [[•]] \mid [[p, j x = m]]
               &\thmref{Rejoin}{J}
\end{align*}

\begin{figure}
  \begin{mathpar}
    \fbox{$[[(s, t) ∈ G]]$} \quad \fbox{$[[(p, q) ∈ D]]$} \hfill \\
    % [[(s, t) ∈ G]] \textit{ iff } \forall [[x : A ∈ G]] \mathpunct{.} [[(s(x), t(x)) ∈ A]] \\
    % \mprset{fraction={{-~} {~-~} {~-}}}
    \inferrule[\ottdrulename{S-nil}]{~}{(•, •) ∈ •}
    \and
    \inferrule[\ottdrulename{S-cons}]
      {[[(s, t) ∈ G]] \and [[(v, w) ∈ A]]}
      %----------------------------------------%
      {[[((s, x ↦ v), (t, x ↦ w)) ∈ G, x : A]]}
    \and
    \inferrule[\ottdrulename{J-nil}]{~}{(•, •) ∈ •}
    \and
    \inferrule[\ottdrulename{J-cons}]
      {[[(p, q) ∈ D]] \and \forall [[v]], [[w]] \mathpunct{.} [[(v, w) ∈ A]] ⇒ [[(joins p in m{x ↦ v}, joins q in n{x ↦ w}) ∈ B]]}
      %-----------------------------------------------%
      {[[((p, j x = m), (q, j x = n)) ∈ D, j : A ↗ B]]}
  \end{mathpar}
  \caption{Logical equivalence of substitution maps and join stacks \thmref{Equivalence}{semCtxt,semDtxt}}
  \Description[]{}
  \label{fig:logeq-subst}
\end{figure}

We extend logical equivalence to substitution maps and join stacks,
relating two of them at a particular context.
\Cref{fig:logeq-subst} gives inductive rules for these logical equivalences.
\Rref{S-nil,S-cons} are equivalent to stating that
$[[(s, t) ∈ G]]$ holds when for all $[[x : A ∈ G]]$, $[[(s(x), t(x)) ∈ A]]$ holds.
\Rref{J-cons} states that we can extend a pair of related join stacks $[[p]]$ and $[[q]]$
by join points $[[m]]$ and $[[n]]$ of type $[[A ↗ B]]$
when the join points themselves are related at $[[B]]$ given arguments related at $[[A]]$
\emph{and} closed over by $[[p]]$ and $[[q]]$.
They need to be closed over since $[[m]]$ and $[[n]]$ themselves may jump to earlier join points.
We can show that substitution maps and join stacks are partial equivalence relations
by induction on their derivations.

\begin{lemma}[Symmetry and transitivity (logical equivalence at contexts)] \label{lem:logeq-subst:PER} \leavevmode
  \begin{itemize}
    \item If $[[(s, t) ∈ G]]$ then $[[(t, s) ∈ G]]$. \thmref{Equivalence}{semCtxt.sym}
    \item If $[[(p, q) ∈ D]]$ then $[[(p, q) ∈ D]]$. \thmref{Equivalence}{semDtxt.sym}
    \item If $[[(s1, s2) ∈ G]]$ and $[[(s2, s3) ∈ G]]$ then $[[(s1, s3) ∈ G]]$. \thmref{Equivalence}{semCtxt.trans}
    \item If $[[(p1, p2) ∈ D]]$ and $[[(p2, p3) ∈ D]]$ then $[[(p1, p3) ∈ D]]$. \thmref{Equivalence}{semDtxt.trans}
  \end{itemize}
\end{lemma}

Using substitution maps and join stacks, we can define semantic equivalence of open terms.
They are also partial equivalence relations,
which follows from \cref{lem:logeq:PER,lem:logeq-subst:PER}.
In all proofs that follow, we freely use symmetry and transitivity without explicit reference.

\begin{definition}[Semantic equivalence of values] \thmref{Equivalence}{semVal} \leavevmode \\
  Values $[[v]]$ and $[[w]]$ are semantically equivalent under context $[[G]]$ at type $[[A]]$,
  written \fbox{$[[G ⊧ v ~ w : A]]$},
  when for all substitution maps $[[(s, t) ∈ G]]$,
  $[[(v{s}, w{t}) ∈ A]]$ holds.
\end{definition}

\begin{definition}[Semantic equivalence of computations] \thmref{Equivalence}{semCom} \leavevmode \\
  Computations $[[m]]$ and $[[n]]$ are semantically equivalent under contexts $[[G]]$ and $[[D]]$ at type $[[B]]$,
  written \fbox{$[[G | D ⊧ m ~ n : B]]$},
  when for all substitution maps $[[(s, t) ∈ G]]$ and join stacks $[[(p, q) ∈ D]]$,
  $[[(joins p in m{s}, joins q in n{t}) ∈ B]]$ holds.
\end{definition}

\begin{lemma}[Symmetry and transitivity (semantic equivalence)] \leavevmode
  \begin{itemize}
    \item If $[[G ⊧ v ~ w : A]]$ then $[[G ⊧ w ~ v : A]]$. \thmref{Equivalence}{semVal.sym}
    \item If $[[G | D ⊧ m ~ n : B]]$ then $[[G | D ⊧ n ~ m : B]]$. \thmref{Equivalence}{semCom.sym}
    \item If $[[G ⊧ v1 ~ v2 : A]]$ and $[[G ⊧ v2 ~ v3 : A]]$ then $[[G ⊧ v1 ~ v3 : A]]$. \thmref{Equivalence}{semVal.trans}
    \item If $[[G | D ⊧ m1 ~ m2 : B]]$ and $[[G | D ⊧ m2 ~ m3 : B]]$ then $[[G | D ⊧ m1 ~ m3 : B]]$. \thmref{Equivalence}{semCom.trans}
  \end{itemize}
\end{lemma}

Finally, we show the fundamental theorem of semantic equivalence:
well-typed terms are semantically equivalent to themselves.

\begin{theorem}[Fundamental theorem of semantic equivalence] \label{thm:semeq} \thmref{Equivalence}{soundness} \leavevmode \\
  If $[[G ⊢ v : A]]$ then $[[G ⊧ v ~ v : A]]$,
  and if $[[G | D ⊢ m : B]]$ then $[[G | D ⊧ m ~ m : B]]$.
\end{theorem}

\begin{proof}
  By induction on the typing derivations of $[[v]]$ and $[[m]]$.
  Letting $[[(s, t) ∈ G]]$ and $[[(p, q) ∈ D]]$,
  the goal is to show that $[[(v{s}, v{t}) ∈ A]]$
  and $[[(joins p in m{s}, joins q in m{t}) ∈* B]]$ hold.
  \begin{itemize}
    \item \textbf{Case} \rref*{T-var}: Holds by $[[(s, t) ∈ G]]$ on the variable.
    \item \textbf{Cases} \rref*{T-unit,T-left,T-right,T-thunk}:
      Hold by definition of the logical relation,
      using the induction hypotheses on any subterms.
    \item \textbf{Cases} \rref*{T-fun,T-ret,T-prod}:
      Hold by \cref{lem:logeq:bwds-joins} with no reduction,
      using the induction hypotheses on subterms.
    \item \textbf{Cases} \rref*{T-app,T-fst,T-snd}:
      By the induction hypotheses on the scrutinee premises,
      they must reduce to related functions, related first pair projections,
      or related second pair projections, respectively.
      Then the goal holds by \cref{lem:logeq:bwds-joins} on these relations,
      reducing by \rref*{E-app}, \rref*{E-fst}, or \rref*{E-snd}, respectively.
    \item \textbf{Cases} \rref*{T-let,T-case}:
      By the induction hypotheses on the scrutinee premises,
      they must reduce to related returns, related left injections,
      or related right injections, respectively.
      Then the goal holds by \cref{lem:logeq:bwds} on these relations,
      reducing by \rref*{E-ret}, \rref*{E-left}, or \rref*{E-right}, respectively.
    \item \textbf{Case} \rref*{T-join}:
      Holds by the induction hypothesis on the join expression body,
      extending semantic equivalence of join stacks
      using the induction hypothesis on the join points.
    \item \textbf{Case} \rref*{T-jump}:
      Holds by $[[(p, q) ∈ D]]$ on the jump variable,
      instantiating the join point by the induction hypothesis on related values. \qedhere
  \end{itemize}
\end{proof}

As a corollary, we have type safety and normalization:
a closed, well-typed computation never evaluates to a stuck term,
and moreover evaluates to a terminal.

\begin{corollary}[Normalization] \thmref{Equivalence}{safety}
  If $[[• | • ⊢ m : B]]$ then $\exists [[tm]], [[m ⇝* tm]]$.
\end{corollary}

\subsection{Semantic equivalence of commuting conversions} \label{sec:proof:cc}

As the translation normalizes with respect to all commuting conversions,
to show that semantic equivalence of the translation,
naturally we need to show semantic equivalence of the commuting conversions.
Recall that with four evaluation contexts and two tail contexts,
there are eight total commuting conversions to handle,
each assuming well-typedness of various subterms.
We present them as derivable rules in \cref{fig:semeq:cc} for legibility.

\begin{figure}
  \begin{mathpar}
    \mprset{fraction={{-~} {~-~} {~-}}}
    \infer*[Right=\ottdrulename{let-let}]
      {[[G | • ⊢ let x ← n in m : F A]] \\
       [[G, y : A | D ⊢ m' : B]]}
      %----------------------------------%
      {[[G | D ⊧ let y ← (let x ← n in m) in m' ~ let x ← n in let y ← m in m' : B]]}
    \and
    \infer*[Right=\ottdrulename{let-app}]
      {[[G | • ⊢ let x ← n in m : A → B]] \\
       [[G ⊢ v : A]]}
      %------------------------------------%
      {[[G | D ⊧ (let x ← n in m) v ~ let x ← n in (m v) : B]]}
    \and
    \infer*[Right=\ottdrulename{let-fst}]
      {[[G | • ⊢ let x ← n in m : B1 & B2]]}
      %------------------------------------%
      {[[G | D ⊧ fst (let x ← n in m) ~ let x ← n in (fst m) : B1]]}
    \and
    \infer*[Right=\ottdrulename{let-snd}]
      {[[G | • ⊢ let x ← n in m : B1 & B2]]}
      %------------------------------------%
      {[[G | D ⊧ snd (let x ← n in m) ~ let x ← n in (snd m) : B2]]}
    \and
    \infer*[Right=\ottdrulename{case-let}]
      {[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : F A]] \\
       [[G, z : A | D ⊢ m : B]]}
      %----------------------------------------------------%
      {[[G | D ⊧ let z ← (case v of inl x ⇒ m1; inr y ⇒ m2) in m \\ ~ case v of inl x ⇒ (let z ← m1 in m); inr y ⇒ (let z ← m2 in m) : B]]}
    \and
    \infer*[Right=\ottdrulename{case-app}]
      {[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : A → B]] \\
       [[G ⊢ w : A]]}
      %------------------------------------------------------%
      {[[G | D ⊧ (case v of inl x ⇒ m1; inr y ⇒ m2) w \\ ~ case v of inl x ⇒ (m1 w); inr y ⇒ (m2 w) : B]]}
    \and
    \infer*[Right=\ottdrulename{case-fst}]
      {[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : B1 & B2]]}
      %------------------------------------------------------%
      {[[G | D ⊧ fst (case v of inl x ⇒ m1; inr y ⇒ m2) \\ ~ case v of inl x ⇒ (fst m1); inr y ⇒ (fst m2) : B1]]}
    \and
    \infer*[Right=\ottdrulename{case-snd}]
      {[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : B1 & B2]]}
      %------------------------------------------------------%
      {[[G | D ⊧ snd (case v of inl x ⇒ m1; inr y ⇒ m2) \\ ~ case v of inl x ⇒ (snd m1); inr y ⇒ (snd m2) : B2]]}
  \end{mathpar}
  \caption{Semantic equivalence of commuting conversions \\
    \thmref{Commutation}{letLet,appLet,fstLet,sndLet,letCase,appCase,fstCase,sndCase}}
  \Description[]{}
  \label{fig:semeq:cc}
\end{figure}

\iffalse
\begin{lemma}[Semantic equivalence of commuting conversions] \label{lem:semeq:cc} \leavevmode \\
  \begin{itemize}
    \item If $[[G | • ⊢ let x ← n in m : F A]]$ and $[[G, y : A | D ⊢ m' : B]]$, then
      $[[G | D ⊧ let y ← (let x ← n in m) in m' ~ let x ← n in let y ← m in m' : B]]$.
    \item If $[[G | • ⊢ let x ← n in m : A → B]]$ and $[[G ⊢ v : A]]$, then
      $[[G | D ⊧ (let x ← n in m) v ~ let x ← n in (m v) : B]]$.
    \item If $[[G | • ⊢ let x ← n in m : B1 & B2]]$, then
      $[[G | D ⊧ fst (let x ← n in m) ~ let x ← n in (fst m) : B1]]$.
    \item If $[[G | • ⊢ let x ← n in m : B1 & B2]]$, then
      $[[G | D ⊧ snd (let x ← n in m) ~ let x ← n in (snd m) : B2]]$.
    \item If $[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : F A]]$ and $[[G, z : A | D ⊢ m : B]]$, then
      $[[G | D ⊧ let z ← (case v of inl x ⇒ m1; inr y ⇒ m2) in m ~ case v of inl x ⇒ (let z ← m1 in m); inr y ⇒ (let z ← m2 in m) : B]]$.
    \item If $[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : A → B]]$ and $[[G ⊢ w : A]]$, then
      $[[G | D ⊧ (case v of inl x ⇒ m1; inr y ⇒ m2) w ~ case v of inl x ⇒ (m1 w); inr y ⇒ (m2 w) : B]]$.
    \item If $[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : B1 & B2]]$, then
      $[[G | D ⊧ fst (case v of inl x ⇒ m1; inr y ⇒ m2) ~ case v of inl x ⇒ (fst m1); inr y ⇒ (fst m2) : B1]]$.
    \item If $[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : B1 & B2]]$, then
      $[[G | D ⊧ snd (case v of inl x ⇒ m1; inr y ⇒ m2) ~ case v of inl x ⇒ (snd m1); inr y ⇒ (snd m2) : B2]]$.
  \end{itemize}
\end{lemma}
\fi

The general strategy to proving these is by using the \cref{thm:semeq} on the typing derivations,
extracting a logical equivalence for the desired type,
applying \cref{lem:logeq:bwds} or \cref{lem:logeq:bwds-joins},
then using the evaluation rules and \cref{lem:eval:merging}
to find the correct evaluation sequence from the left and right sides of the lemma statement
to the respective sides of the extracted logical equivalence.
We step through only the proof of \rref*{let-app} as a representative case.

\begin{proof}
  Because substitution maps and join stacks don't play much of a role,
  we mostly ignore them here.
  The goal is then to show that $[[(let x ← n in m) v]]$
  is equivalent to $[[let x ← n in (m v)]]$,
  knowing that all subterms are well typed.
  By \cref{thm:semeq}, we have that $[[n]]$ reduces to some $[[return w]]$,
  and that $[[m{x ↦ w}]]$ reduces to some $[[λy. m']]$.
  Then we know that the right-hand side reduces by \rref*{E-ret,E-app}
  to $[[m'{y ↦ v}]]$.
  We also have that $[[let x ← n in m]]$ reduces to $[[m{x ↦ w}]]$ by \rref*{E-ret}.
  Then we know that the left-hand side reduces by \rref*{E-app} also to $[[m'{y ↦ v}]]$.
  Therefore, by \cref{lem:logeq:bwds-joins},
  the left- and right-hand sides are equivalent.
\end{proof}

Although our translation doesn't involve commuting join points,
we do require a corresponding semantic equivalence to unnest join points,
stated in \cref{fig:semeq:join-join}.

\begin{figure}[h]
  \begin{mathpar}
    \mprset{fraction={{-~} {~-~} {~-}}}
    \infer[\ottdrulename{join-join}]
      {[[G, x1 : A1 | D ⊢ m1 : B]] \\
       [[G, x2 : A2 | D, j1 : A1 ↗ B ⊢ m2 : B]] \\
       [[G | D, j2 : A2 ↗ B ⊢ m : B]]}
      {[[G | D ⊧ join j2 x2 = (join j1 x1 = m1 in m2) in m ~ join j1 x1 = m1 in join j2 x2 = m2 in m : B]]}
  \end{mathpar}
  \caption{Semantic equivalence of commuting join points \thmref{Commutation}{joinJoin}}
  \Description[]{}
  \label{fig:semeq:join-join}
\end{figure}

On the right-hand side, $[[m]]$ can't directly jump to $[[j1]]$,
since it isn't in scope in its typing,
so if $[[m]]$ doesn't jump to $[[j2]]$, then both join points can be dropped.
In the mechanization, this isn't so easy to prove,
since we're using de Bruijn indexed jump variables.
Consequently, $[[m]]$ must be explicitly weakened on the right-hand side,
and to show that join points can be dropped,
we first need to show that evaluation preserves weakening.
These technical details aside, the proof proceeds similarly to those for the commuting conversions.

\subsection{Semantic equivalence of plugging continuations} \label{sec:proof:plug}

Just as the \nameref{thm:semeq} requires related substitution maps and related join stacks,
for the final proof in the next section, we need a notion of related continuations.
Rather than first defining a logical equivalence over continuations,
we directly define semantic equivalence in a way that incorporates plugging.
Here, $[[K{s}]]$ denotes applying the substitution map $[[s]]$
to all value and computation subterms of $[[K]]$.

\begin{definition}[Semantic equivalence of continuations] \thmref{Soundness}{semK} \leavevmode \\
  Continuations $[[K1]]$ and $[[K2]]$ are semantically equivalent
  under $[[G]]$ and $[[D]]$ at type $[[B1 ⇒ B2]]$,
  written \fbox{$[[G | D ⊧ K1 ~ K2 : B1 ⇒ B2]]$},
  when for all substitution maps $[[(s, t) ∈ G]]$, join stacks $[[(p, q) ∈ D]]$,
  and computations $[[(n1, n2) ∈* B1]]$,
  $[[(joins p in K{s}[n1], joins q in K{t}[n2]) ∈ B2]]$ holds.
\end{definition}

A fundamental theorem for semantic equivalence of continuations holds as well,
which relies on the corresponding theorem for terms,
as well as congruence of evaluating under plugging.

\begin{lemma}[\textsc{E-plug}] \label{lem:E-plug} \thmref{CCNF}{Evals.plug} \leavevmode \\
  If $[[n1 ⇝* n2]]$, then $[[ K[n1] ⇝* K[n2] ]]$,
  by induction on the structure of $[[K]]$.
\end{lemma}

\begin{theorem}[Fundamental theorem of semantic equivalence of continuations] \label{thm:semeq:K} \leavevmode \\
  If $[[G | D ⊢ K : B1 ⇒ B2]]$ then $[[G | D ⊧ K ~ K : B1 ⇒ B2]]$. \thmref{Soundness}{soundK}
\end{theorem}

\begin{proof}
  By induction on the typing derivation of $[[K]]$.
  In the \rref*{K-app} case, use \cref{thm:semeq} on the value argument,
  and in the \rref*{K-let} case, use \cref{thm:semeq} on the computation body.
  In the \rref*{K-app,K-fst,K-snd} cases,
  use \nameref{lem:E-plug} to reduce under the rest of the continuation.
\end{proof}

Plugging semantically equivalent computations into both
the same continuation and equivalent continuations
then yields equivalent computations
as long as substitution commutes with plugging.

\begin{lemma}[Substitution commutes with plugging] \label{lem:subst-plug} \thmref{CCNF}{substPlug} \leavevmode \\
  $[[(K[n]){s}]] = [[(K{s})[n{s}] ]]$,
  by induction on the structure of $[[K]]$.
\end{lemma}

\begin{lemma}[Semantic equivalence of plugging] \label{lem:semeq:plug} \thmref{Soundness}{semK.plug} \leavevmode \\
  If $[[G | D ⊧ K1 ~ K2 : B1 ⇒ B2]]$ and $[[G | • ⊧ n1 ~ n2 : B1]]$,
  then $[[G | D ⊧ K1[n1] ~ K2[n2] : B2]]$, \linebreak[0]
  trivially after rewriting by \cref{lem:subst-plug}.
\end{lemma}

\begin{corollary} \label{cor:semeq:plug} \thmref{Soundness}{semPlug}
  If $[[G | D ⊢ K : B1 ⇒ B2]]$ and $[[G | • ⊧ n1 ~ n2 : B1]]$,
  then $[[G | D ⊧ K[n1] ~ K[n2] : B2]]$,
  using \cref{lem:semeq:plug} and \cref{thm:semeq:K}.
\end{corollary}

\subsection{Commuting conversion normalization is semantically equivalent to plugging} \label{sec:proof:end}

Now that we have both semantic equivalence of commuting conversions and of plugging,
we use them together to show that plugging commutes with tail contexts.

\begin{lemma}[Semantic equivalence of plugging let expressions] \label{lem:plug-let} \thmref{Soundness}{semKletin} \leavevmode \\
  If $[[G | D ⊢ K : B1 ⇒ B2]]$ and $[[G | • ⊢ let x ← n in m : B1]]$, \\
  then $[[G | D ⊧ K[let x ← n in m] ~ let x ← n in K[m] : B2]]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[K]]$.
  In the \rref*{K-nil} case, this holds by \cref{thm:semeq}.
  In all other cases, the left-hand side involves a subterm of the form
  $[[let y ← (let x ← n in m) in m']]$, or
  $[[(let x ← n in m) v]]$, or
  $[[fst (let x ← n in m)]]$, or
  $[[snd (let x ← n in m)]]$,
  so we use derived \rref{let-let,let-app,let-fst,let-snd} respectively to commute them.
  For case \rref*{K-let}, we are done;
  for the remaining cases, we require \cref{cor:semeq:plug} to commute under a plugged $[[K]]$,
  then use the induction hypothesis to transitively connect to the right-hand side.
\end{proof}

\begin{lemma}[Semantic equivalence of plugging case expressions] \label{lem:plug-case} \thmref{Soundness}{semKcase} \leavevmode \\
  If $[[G | D ⊢ K : B1 ⇒ B2]]$ and $[[G | • ⊢ case v of inl x ⇒ m1; inr y ⇒ m2 : B1]]$, \\
  then $[[G | D ⊧ K[case v of inl x ⇒ m1; inr y ⇒ m2] ~ case v of inl x ⇒ K[m1]; inr y ⇒ K[m2] : B2]]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[K]]$,
  using \cref{thm:semeq,cor:semeq:plug}
  along with derived \rref{case-let,case-app,case-fst,case-snd}
  similarly to \cref{lem:plug-let}.
\end{proof}

These two lemmas suffice to prove the desired equivalence
for a na\"ive translation that duplicates continuations instead of using join points.
To handle join points, we need one more lemma that gives an equivalence
between a translation that doesn't use a join point and one that does.

\begin{lemma}[Jump equivalence of plugging] \label{lem:plug-jump} \thmref{Soundness}{semKjoin} \leavevmode \\
  If $[[G | D ⊢ K : B1 ⇒ B2]]$, $[[G | • ⊢ n : B1]]$,
  and $[[K]] \equiv [[ (let x ← □ in m) [k1] - [ki] ]]$,
  then $[[G | D ⊧ K[n] ~ join j x = m in K'[n] : B2 ]]$,
  where $[[K']] \equiv [[ (let x ← □ in jump j x) [k1] - [ki] ]]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[K]]$.
  The \rref{K-let} case uses \cref{thm:semeq} on the typing derivation of $[[n]]$
  to show it must evaluate to some $[[return v]]$;
  then both sides evaluate to $[[m{x ↦ v}]]$,
  and we get the equivalence from \cref{thm:semeq} on the typing derivation of $[[m]]$.
  The remaining cases follow from the induction hypotheses.
\end{proof}

\begin{lemma}[Jump equivalence of the translation] \label{lem:plug-ccnf} \thmref{Soundness}{soundCCjoin} \leavevmode \\
  Suppose that $[[m]]$ contains no join points or jumps.
  If $[[G | D ⊢ K : B1 ⇒ B2]]$, $[[G | D ⊢ m : B1]]$,
  and $[[K]] \equiv [[ (let x ← □ in m') [k1] - [ki] ]]$,
  then $[[G | D ⊧ ⟦m⟧K ~ join j x = m' in ⟦m⟧K' : B2 ]]$,
  where $[[K']] \equiv [[ (let x ← □ in jump j x) [k1] - [ki] ]]$.
\end{lemma}

\begin{proof}
  By induction on the typing derivation of $[[m]]$.
  \begin{itemize}
    \item \textbf{Cases} \rref*{T-force,T-fun,T-ret,T-prod}:
      Hold directly from \cref{lem:plug-jump},
      using \cref{lem:preservation} to type translated subterms.
    \item \textbf{Cases} \rref*{T-app,T-fst,T-snd}:
      Hold directly from the induction hypotheses.
    \item \textbf{Case} \rref*{T-let}:
      The goal is to show that $[[⟦let y ← n in m⟧K]]$
      is semantically equivalent to $[[join j x = m' in ⟦let y ← n in m⟧K']]$,
      which holds by the following chain of equivalences.
      \begin{align}
        &[[⟦let y ← n in m⟧K]] \nonumber \\
        &= [[⟦n⟧ (let y ← □ in ⟦m⟧K)]] \tag{\textit{by definition}} \\
        &\sim [[join j' y = ⟦m⟧K in ⟦n⟧ (let y ← □ in jump j' y)]] \tag{\textit{by IH on $[[n]]$}} \\
        &\sim [[join j' y = (join j x = m' in ⟦m⟧K') in ⟦n⟧ (let y ← □ in jump j' y)]] \tag{\textit{by IH on $[[m]]$}} \\
        &\sim [[join j x = m' in join j' y = ⟦m⟧K' in ⟦n⟧ (let y ← □ in jump j' y)]] \tag{\textit{by \rref*{join-join}}} \\
        &\sim [[join j x = m' in ⟦n⟧ (let y ← □ in ⟦m⟧K')]] \tag{\textit{by IH on $[[n]]$}} \\
        &= [[join j x = m' in ⟦let y ← n in m⟧K']] \tag{\textit{by definition}}
      \end{align}
    \item \textbf{Case} \rref*{T-case}:
      Let the translated computation be $[[case v of inl y ⇒ m1; inr y ⇒ m2]]$.
      There are two subcases depending on what $[[m']]$ is.
      \begin{itemize}
        \item If $[[m']] \equiv [[jump j' w]]$,
          then by the translation, the left-hand side is
          \[ [[case ⟦v⟧ of inl y ⇒ ⟦m1⟧K; inr y ⇒ ⟦m2⟧K]], \]
          and the right-hand side is
          \[ [[join j x = m' in case ⟦v⟧ of inl y ⇒ ⟦m1⟧K'; inr y ⇒ ⟦m2⟧K']]. \]
          By \cref{thm:semeq}, we know $[[⟦v⟧]]$ reduces to either some $[[inl w]]$ or $[[inr w]]$.
          WLOG, supposing the former, it then suffices to show that
          $[[⟦m1⟧K {y ↦ w}]]$ is semantically equivalent to $[[join j x = m' in ⟦m1⟧K' {y ↦ w}]]$,
          which holds by the induction hypothesis on $[[m1]]$.
        \item Otherwise, both the left- and right-hand sides are
          \[ [[join j x = m' in case ⟦v⟧ of inl y ⇒ ⟦m1⟧K'; inr y ⇒ ⟦m2⟧K']], \]
          which are equivalent by \cref{thm:semeq},
          using \cref{lem:preservation} for the translated subterms. \qedhere
      \end{itemize}
  \end{itemize}
\end{proof}

Finally, we have all pieces to prove the main theorem:
the translation under continuation $[[K]]$ is semantically equivalent to plugging into $[[K]]$.
The equivalence we want follows from instantiating by the empty continuation.

\begin{theorem} \thmref{Soundness}{soundCC}
  Suppose that $[[v]]$ and $[[m]]$ are terms containing no join points and jumps,
  and $[[K1]], [[K2]]$ are continuations that may contain join points and jumps.
  \begin{itemize}
    \item If $[[G ⊢ v : A]]$ then $[[G ⊧ v ~ ⟦v⟧ : A]]$.
    \item If \mbox{$[[G | • ⊢ m : B1]]$}, \mbox{$[[G | D ⊢ K1 : B1 ⇒ B2]]$},
      \mbox{$[[G | D ⊢ K2 : B1 ⇒ B2]]$}, \\ and
      \mbox{$[[G | D ⊧ K1 ~ K2 : B1 ⇒ B2]]$}, then
      $[[G | D ⊧ K1[m] ~ ⟦m⟧ K2 : B2]]$.
  \end{itemize}
\end{theorem}

\begin{proof}
  By mutual induction on the typing derivations of $[[v]]$ and $[[m]]$.
  \begin{itemize}
    \item \textbf{Case} \rref*{T-var}:
      Holds by logical equivalence of substitution maps.
    \item \textbf{Case} \rref*{T-unit}: Trivial.
    \item \textbf{Cases} \rref*{T-force,T-fun,T-ret,T-prod}:
      Hold by \cref{lem:semeq:plug} and the induction hypotheses.
    \item \textbf{Cases} \rref*{T-left,T-right,T-thunk,T-app,T-fst,T-snd}:
      Hold by the induction hypotheses.
    \item \textbf{Case} \rref*{T-let}:
      The goal is to show that $[[ K[let x ← n in m] ]]$
      is equivalent to $[[⟦let x ← n in m⟧K]]$,
      which holds by the following chain of equivalences.
      \begin{align*}
        [[ K[let x ← n in m] ]] \nonumber
        &\sim [[ let x ← n in K[m] ]] \tag{\textit{by \cref{lem:plug-let}}} \\
        &\sim [[ let x ← n in ⟦m⟧K ]]
        = [[ (let x ← □ in ⟦m⟧K)[n] ]] \tag{\textit{by IH on $[[m]]$}} \\
        &\sim [[⟦n⟧ (let x ← □ in ⟦m⟧K)]]
        = [[⟦let x ← n in m⟧K]] \tag{\textit{by IH on $[[n]]$}}
      \end{align*}
    \item \textbf{Case} \rref*{T-case}:
      The goal is to show that $[[ K[case v of inl y ⇒ m1; inr y ⇒ m2] ]]$
      is equivalent to $[[⟦case v of inl y ⇒ m1; inr y ⇒ m2⟧K]]$.
      By \cref{lem:plug-case}, the left-hand side is equivalent to
      $[[ case v of inl y ⇒ K[m1]; inr y ⇒ K[m2] ]]$.
      Furthermore, by the induction hypotheses on the subterms,
      this is equivalent to $[[case ⟦v⟧ of inl y ⇒ ⟦m1⟧K; inr y ⇒ ⟦m2⟧K]]$.
      It then suffices to prove this equivalent to the right-hand side.
      There are two subcases depending on what $[[K]]$ is.
      \begin{itemize}
        \item If $[[K]] \equiv [[ □ [k1] - [ki] ]]$
          or $[[K]] \equiv [[ (let x ← □ in jump j v) [k1] - [ki] ]]$,
          then the right-hand side is
          $[[case ⟦v⟧ of inl y ⇒ ⟦m1⟧K; inr y ⇒ ⟦m2⟧K]]$,
          and we are done.
        \item Otherwise, $[[K]] \equiv [[ (let x ← □ in m') [k1] - [ki] ]]$.
          Letting $[[K']] \equiv [[ (let x ← □ in jump j x) [k1] - [ki] ]]$,
          the right-hand side is
          \[ [[join j x = m' in case ⟦v⟧ of inl y ⇒ ⟦m1⟧K'; inr y ⇒ ⟦m2⟧K' ]]. \]
          By \cref{thm:semeq}, we know $[[⟦v⟧]]$ reduces to either some $[[inl w]]$ or $[[inr w]]$.
          WLOG, supposing the former, it then suffices to show that
          $[[⟦m1⟧K {y ↦ w}]]$ is equivalent to $[[join j x = m' in ⟦m1⟧K' {y ↦ w}]]$.
          Extending the substitution map with $[[y ↦ w]]$
          (noting that $[[y]]$ is only free in $[[m1]]$),
          this equivalence holds by \cref{lem:plug-ccnf}. \qedhere
      \end{itemize}
  \end{itemize}
\end{proof}

\begin{corollary} \label{cor:semeq-ccnf} \thmref{Soundness}{soundCCnil}
  Suppose $[[m]]$ contains no join points and jumps. \\
  If \mbox{$[[G | • ⊢ m : B]]$} then \mbox{$[[G | • ⊧ m ~ ⟦m⟧ □ : B]]$}.
\end{corollary}

At last we are able to prove \cref{thm:ground-run}, restated below,
with one more minor lemma.

\begin{lemma}[Equivalent ground values are equal] \label{lem:logeq:gval} \thmref{Soundness}{$\mathcal{V}$.ground} \leavevmode \\
  If $[[(v, w) ∈ T]]$ then $[[v]] = [[w]]$,
  proven by induction on $[[T]]$.
\end{lemma}

\begin{theorem} \thmref{Soundness}{retGround} \leavevmode \\
  Given $[[m]]$ such that $[[• | • ⊢ m : F T]]$,
  if $[[m ⇓ return v]]$, then $[[⟦ m ⟧ □ ⇓ return v]]$.
\end{theorem}

\begin{proof}
  From \cref{cor:semeq-ccnf}, we have $[[• | • ⊧ m ~ ⟦m⟧ □ : F T]]$.
  Instantiating with empty substitution maps and empty join stacks,
  we have $(m, ⟦m⟧ □) ∈* F T$.
  By inversion, we know that there exists some $([[w1]], [[w2]]) ∈ T$
  such that $[[m ⇓ return w1]]$ and $[[⟦m⟧ □ ⇓ return w2]]$.
  By \cref{lem:norm:det}, we have $[[v]] = [[w1]]$,
  and by \cref{lem:logeq:gval}, we have $[[w1]] = [[w2]]$.
  Therefore, $[[⟦m⟧ □ ⇓ return v]]$.
\end{proof}

\section{Discussion} \label{sec:discuss}

\subsection{Case-of-case} \label{sec:discuss:case-case}

In the lambda calculus with conditional expressions,
the \emph{case-of-case} transformation commutes
a conditional whose scrutinee is another conditional.
The na\"ive transformation directly moves the outer conditional into the branches of the inner,
duplicating the code in its branches.
%
\usetagform{brack}
\begin{align}
  &[[if (if e1 then e2 else e3) then e4 else e5]] \nonumber \\
  &\Longrightarrow [[if e1 then (if e2 then e4 else e5) else (if e3 then e4 else e5)]] \label{eq:if-if}
\end{align}
\usetagform{default}
%
Let-binding the outer branches avoids this duplication.
Notably, doing so doesn't touch the direct scrutinization of $[[e2]]$ and $[[e3]]$,
so if they are literal $[[true]]$ or $[[false]]$ values,
then those branches can be inlined to just $[[x]]$ or $[[y]]$.
%
\usetagform{brack}
\begin{align}
  &[[if (if e1 then e2 else e3) then e4 else e5]] \nonumber \\
  &\Longrightarrow [[let x = e4 in let y = e5 in if e1 then (if e2 then x else y) else (if e3 then x else y)]] \label{eq:let-if-if}
\end{align}
\usetagform{default}
If we translate the left-hand lambda expression to a CBPV term,
both CBV and CBN translations yield a term of the following shape.
%
\usetagform{brack}
\begin{align}
  &[[let y ← (let x ← m1 in if x then m2 else m3) in if y then m4 else m5]] \label{eq:CBPV-if-if}
\end{align}
\usetagform{default}
%
CC-normalizing this term moves the outer let binding into the branches of the conditional on $[[x]]$,
with jumps to avoid duplication.
%
\usetagform{brack}
\begin{align}
  &[[let x ← m1 in join j y = if y then m4 else m5 in _]] \nonumber \\
  &\quad [[if x then (let y ← m2 in jump j y) else (let y ← m3 in jump j y)]] \label{eq:CC-if-if}
\end{align}
\usetagform{default}
Unfortunately, even if $[[m2]]$ is the computation $[[return true]]$,
inlining it will only reduce the branch down to $[[jump j true]]$,
whose evaluation will still need to jump to the conditional in the join point
that could otherwise have been inlined away statically.
What we would like is to create separate join points for $[[m4]]$ and $[[m5]]$
and jump to them individually to permit the kind of inlining above,
similar to the right-hand side of \cref{eq:let-if-if}.
%
\usetagform{brack}
\begin{align}
  &[[let x ← m1 in join j4 = m4 in join j5 = m5 in _]] \nonumber \\
  &\quad [[if x then (let y ← m2 in if y then jump j4 else jump j5) _]] \nonumber \\
  &\quad \phantom{[[if x _]]} [[else (let y ← m3 in if y then jump j4 else jump j5)]] \label{eq:CC2-if-if}
\end{align}
\usetagform{default}

Therefore, we prove a semantic equivalence between \cref{eq:CC-if-if} and \cref{eq:CC2-if-if},
generalizing to case expressions.
Consequently, a transformation from the former to the latter is valid,
and we recover the desired case-of-case transformation.

\begin{lemma}[Case-of-case] \label{lem:case-case} \thmref{Commutation}{caseCase}
  Suppose the following hold:
  \begin{itemize}
    \item $[[G ⊢ v : A3 + A4]]$
    \item $[[G, y1 : A1 | D ⊢ m1 : B]]$
    \item $[[G, y2 : A2 | D ⊢ m2 : B]]$
    \item $[[G, y3 : A3 | • ⊢ m3 : F (A1 + A2)]]$
    \item $[[G, y4 : A4 | • ⊢ m4 : F (A1 + A2)]]$
  \end{itemize}
  Then under contexts $[[G]], [[D]]$, the computation
  \begin{align*}
    &[[join j x = case x of inl y1 ⇒ m1; inr y2 ⇒ m2 in _]] \\
    &\quad [[case v of inl y3 ⇒ (let x ← m3 in jump j x); inr y4 ⇒ (let x ← m3 in jump j x)]]
  \end{align*}
  is semantically equivalent at type $[[B]]$ to the computation
  \begin{align*}
    &[[join j1 y1 = m1 in join j2 y2 = m2 in _]] \\
    &\quad [[case' v of inl y3 ⇒ (let x ← m3 in case x of inl y1 ⇒ jump j1 y1; inr y2 ⇒ jump j2 y2);
                        inr y4 ⇒ (let x ← m4 in case x of inl y1 ⇒ jump j1 y1; inr y2 ⇒ jump j2 y2)]]
  \end{align*}
\end{lemma}

This transformation applies generally to case-of-case-of-case and so forth.
The translation to CBPV gives join points that contain join points
that contain case expressions and so forth.
Unnesting these join points with \rref*{join-join}
followed by \cref{lem:case-case} yields the desired transformation.

\subsection{Inlining and CCNF}

\iffalse
\begin{figure}
  \begin{align}
    [[join j x = m in jump j v & ≡ m{x ↦ v}]]   \tag{\ottdrulename{Eq-jump}} \\
    [[join j' x = m' in jump j v & ≡ jump j v]] \tag{\ottdrulename{Eq-skip}} \\
    [[join j' x = m' in tm & ≡ tm]]             \tag{\ottdrulename{Eq-drop}}
  \end{align}
  \begin{mathpar}
    \inferrule[\ottdrulename{Eq-join-cong}]
      {[[m1 ≡ m2]] \\
       [[n1 ≡ n2]]}
      {[[join j x = m1 in n1 ≡ join j x = m2 in n2]]}
    \and
    \inferrule[\ottdrulename{Eq-jump-cong}]
      {[[v ≡ w]]}
      {[[jump j v ≡ jump j w]]}
  \end{mathpar}
  \caption{Equational rules for join points and jumps}
  \Description[]{}
  \label{fig:equational}
\end{figure}

Inlining opportunities correspond to $\beta$-redexes that appear in subterms.
They are justified by the equational theory, which in turn is justified by semantic equivalence.
We extend the equational theory of CBPV with rules for join points and jumps in \cref{fig:equational}
and show that syntactically equivalent terms are semantically equivalent.

\TODO: It turns out this requires logical equivalence on open terms,
which amounts to proving strong normalization, so we're not doing that.

\begin{lemma}[Soundness of equational theory] \leavevmode
  \begin{itemize}
    \item If $[[G ⊢ v : A]]$, $[[G ⊢ w : A]]$, and $[[v ≡ w]]$, then $[[G ⊧ v ~ w : A]]$.
    \item If $[[G | D ⊢ m : B]]$, $[[G | D ⊢ n : B]]$, and $[[m ≡ n]]$, then $[[G | D ⊧ m ~ n : B]]$.
  \end{itemize}
\end{lemma}
\fi

Recall that new opportunities for inlining revealed by CC-normalization preserve CCNF,
since they only occur in tail positions.
However, subsequent inlinings that force direct thunks may violate CCNF.
Consider the following sequence of a commuting conversion,
followed by an inlining that reduces a function,
followed by an inlining that forces a thunk.
%
\begin{align}
  &[[(let x ← n1 in (λy'. let y ← y'! in m1)) {let z ← n2 in m2}]] \nonumber \\
  &\Longrightarrow [[let x ← n1 in ((λy'. let y ← y'! in m1) {let z ← n2 in m2})]] \tag{\textit{commute}} \\
  &\Longrightarrow [[let x ← n1 in (let y ← {let z ← n2 in m2}! in m1)]] \tag{\rref*{E-app}} \\
  &\Longrightarrow [[let x ← n1 in (let y ← (let z ← n2 in m2) in m1)]] \tag{\rref*{E-force}}
\end{align}

The resulting term after commuting and inlining once is still in CCNF.
But if we force the thunk,
we end up with a nested let expression, which isn't in CCNF.
Therefore, renormalization may be required only after forcing thunks
that appear in $[[n]]$ positions as a result of inlining.

\subsection{Commuting constructors} \label{sec:discuss:constr}

Our notion of commuting conversions only involves elimination forms,
as they make up evaluation contexts $[[E]]$ and tail contexts $[[L]]$.
Other work \citep{CBPV,CBPV-Coq} also consider equations which
commuting elimination forms with introduction forms,
specifically computation constructors in tail position,
listed below.
In particular, the first equation is part of \citeauthor{CBPV}'s \emph{sequencing laws}.
%
\begin{align*}
  [[let x ← n in λy. m]]
    &\Longleftrightarrow [[λy. let x ← n in m]] \\
  [[case v of inl y ⇒ λx. m1 ; inr z ⇒ λx. m2]]
    &\Longleftrightarrow [[λx. case v of inl y ⇒ m1 ; inr z ⇒ m2]] \\
  [[let x ← n in ⟨m1, m2⟩]]
    &\Longleftrightarrow [[⟨let x ← n in m1, let x ← n in m2⟩]] \\
  [[case v of inl y ⇒ ⟨m1, m2⟩ ; inr z ⇒ ⟨m3, m4⟩]]
    &\Longleftrightarrow \\
    \mathclap{[[⟨case v of inl y ⇒ m1 ; inr z ⇒ m3, case v of inl y ⇒ m2 ; inr z ⇒ m4⟩]]}
\end{align*}

We don't consider these because it's unclear which direction to pick and what benefits they provide.
Going left to right, the case equations only apply when the branches are both exactly an introduction form,
and these na\"ive pair equations duplicate code,
so typing and evaluation would need to be extended
to permit creating join points from the components and jumping from within pairs.
Going right to left, the pair equations only apply when the projections both eliminate exactly the same thing.
Either way, they are sensitive to slight syntactic variation, \eg permuted let bindings.
Furthermore, neither direction appears to reveal optimization opportunities.

\subsection{Extensions and future work} \label{sec:future}

\paragraph{Effects}
Like \citet{CBPV-Coq}, the CBPV we consider doesn't include effects.
However, by inspection, we can see that commuting conversions are effect safe.
For instance, considering $[[let y ← (let x ← n1 in n2) in m]]$,
if $[[n1]]$, $[[n2]]$, and $[[m]]$ contained effects,
they would be executed in that very order according to the evaluation semantics
both before and after commutation.

Not all semantically equivalent computations preserve effect order.
Given $[[n1]]$ and $[[n2]]$ where neither $[[x]]$ nor $[[y]]$ are free,
$[[let x ← n1 in let y ← n2 in m]]$ is semantically equivalent to
$[[let y ← n2 in let x ← n1 in m]]$,
but would swap the order of effects in $[[n1]]$ and $[[n2]]$.
We believe that CC-normalization doesn't perform extraneous reordering transformations,
but rigorously proving it effect safe requires incorporating effects into the logical relation.

\paragraph{Stack usage}
Commuting conversions optimize stack usage.
For the CBV lambda calculus, where the A-reductions of ANF are commuting conversions,
\citet{ANF-dead} views ANF as the A-normalization of monadic normal form (MNF),
the syntactic form of the monadic meta-language by \citet{MNF}
that binds intermediate computations.
He shows that first taking A-reduction steps from MNF to ANF
optimizes stack usage in comparison to evaluating the original MNF term
under stack machine semantics.

Similarly, we can see that our CBPV commuting conversions may also reduce stack usage.
For instance, considering $[[let y ← (let x ← n1 in n2) in m]]$,
stack machine evaluation would first push $[[let y ← □ in m]]$ onto the stack,
followed by $[[let x ← □ in n2]]$,
before evaluating $[[n1]]$ and popping these two stack frames.
In contrast, evaluating $[[let x ← n1 in let y ← n2 in m]]$
pushes $[[let x ← □ in let y ← n2 in m]]$ onto the stack,
evaluates $[[n]]$, pops this stack frame,
then pushes $[[let y ← □ in m]]$ next,
using one fewer total stack frame.

Because our translation is a single-pass transformation that uses a continuation
rather than a sequence of commuting conversions,
which traverses the term each time,
showing that CC-normalized computations optimize stack usage is nontrivial.
It may require going through an intermediate big-step semantics to track maximum stack usage,
similar to how \citet{cost} use big-step to track space and time usage
in their cost model of CBPV.

\paragraph{Compilation to assembly}
One way to reap the benefits of the way commuting conversions unnest computations
is to compile onwards to a lower-level assembly-like language.
A potential compilation target is the lower-level ``linearized CBPV'' proposed by \citet{CBPV-STAL},
which is a stack machine language with explicit push/pop and jump operations.
We conjecture that CC-normalization prior to compilation to this language would optimize stack usage,
and that our jumps can be compiled directly to its jumps.

\section{Related Work} \label{sec:related}

\Citet{CBPV-Coq} mechanize in Rocq a vast amount of metatheory for call-by-push-value,
including normalization and observational equivalence.
Our work builds on their design of logical equivalence between terms.
They show a number of commuting conversions as semantic equivalences,
namely commuting let-bound let expressions (Lemma 8.4, Equation 5)
and function application of let expressions (Lemma 8.6, Equation 1),
but are not comprehensive in listing all possible commuting conversions systematically as we have done.

Our join points and their typing judgements with a separate join point typing context
are inspired by \citet{join}, who add join points and jumps to System F,
and implement their system in the Haskell compiler GHC.
We simplify the addition by only allowing jumps in tail position,
while they permit jumps in evaluation contexts.
They perform their optimizations equation by equation,
which yields intermediate steps that require this permissiveness,
such as the following.
%
\begin{align*}
  [[(join j x = m in jump j v) w]] &\Longrightarrow [[join j x = m w in (jump j v) w]] \\
                                   &\Longrightarrow [[join j x = m w in jump j v]]
\end{align*}
Because we present instead a single-pass algorithm,
we never produce such intermediate steps that need to be typeable,
so we are able to eliminate them from our syntax outright.
Doing so also simplifies typing:
their jumps need to be typeable with arbitrary types,
which they implement using type polymorphism,
while our jumps are always in tail position
and fixed to the return type of the join point they jump to.

Their work on join points is in contrast to earlier work by \citet{continued},
who argues for CPS instead of direct-style using second-class continuations,
and from whom we borrow the terminology \emph{CC-normalization}.
\Citet{wowo} combine ideas from both using control operators
that bind second-class continuations, using them as join points.
Their system allows for both direct style and continuation-passing style optimizations;
this is not directly applicable to CBPV, which is already in direct style
by virtue of binding intermediate computations.
However, the corresponding dual of CBPV is stack-passing style \citep{compiling},
and it would be interesting to see whether a similar technique could be applied.
The Zydeco project is ongoing work implementing a compiler from CBPV to stack-passing style \citep{zydeco}.

\section{Conclusion} \label{sec:conclusion}

In this paper, we looked at commuting conversions for call-by-push-value,
which are syntactic transformations that preserve evaluation.
By commuting evaluation contexts into tail positions,
we unnest computations and expose inlining opportunities.
We have identified a commuting conversion normal form for CBPV
and presented a single-pass transformation into CCNF.
To avoid code duplication without incurring additional closures,
we used a separate join point construct that avoids creating new thunks.
We have shown that the translation preserves not just typing but also evaluation,
using a logical equivalence to prove that
the translation of a term is equivalent to itself.
Our results are entirely mechanized in Lean 4.

\section{Data-Availability Statement}

We will submit an artifact for evaluation consisting of our Lean 4 proof development,
provided as supplementary materials for the paper submission.

\bibliography{main}

\end{document}

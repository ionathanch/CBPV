\newif\ifarxiv
\arxivfalse

% acmart now uses unicode-math, and mathtools needs to be loaded before it
\RequirePackage{mathtools}
\documentclass[acmsmall,screen,review,anonymous,nonacm]{acmart}
\settopmatter{printacmref=false, printccs=false, printfolios=true}

\ifarxiv
\pdfoutput=1
\nolinenumbers
\usepackage[T1]{fontenc}
\usepackage[scale=0.92]{inconsolata}
\else
\usepackage{fontspec}
\setmonofont[Scale=MatchLowercase]{inconsolata}
\fi

\usepackage[supertabular]{ottalt}
\let\newlist\relax
\let\renewlist\relax
\usepackage[capitalize,nameinlink,noabbrev]{cleveref}
\usepackage{enumitem,booktabs,xspace,doi}
\usepackage{mathpartir,stmaryrd,colonequals}
\usepackage[bottom,flushmargin,multiple,para]{footmisc} % para spacing is weird and ugly

\newcommand{\repo}{https://github.com/ionathanch/CBPV}
\newcommand{\lang}{A-CBPV\@\xspace}
\newcommand{\titlebreak}{\texorpdfstring{\\}{}}
\newcommand{\TODO}{\textcolor{red}{\textbf{\textsf{TODO}}}\@\xspace}
\newcommand{\ie}{\textit{i.e.}\@\xspace}
\newcommand{\eg}{\textit{e.g.}\@\xspace}
\newcommand{\etal}{\textit{et al.}\@\xspace}
\newcommand{\opcit}{\textit{op. cit.}\@\xspace}
\newcommand{\vs}{\textit{vs.}\@\xspace}
\newcommand{\ala}{\textit{\`a la}\@\xspace}
\newcommand{\apriori}{\textit{a priori}\@\xspace}
\newcommand{\fstar}{F$^\star$\@\xspace}
\newcommand{\welltyped}{well-\hspace{0pt}typed\@\xspace}
\newcommand{\wellfounded}{well-\hspace{0pt}founded\@\xspace}
\newcommand{\wellfoundedness}{well-\hspace{0pt}foundedness\@\xspace}
\newcommand{\wellformedness}{well-\hspace{0pt}formedness\@\xspace}
\newcommand{\welldefinedness}{well-\hspace{0pt}definedness\@\xspace}
\newcommand{\crude}{crude-\hspace{0pt}but-\hspace{0pt}effective\@\xspace}

\newcommand{\thmref}[2]{%
  $\langle$\textnormal{\texttt{\href{\repo/tree/main/src/#1}{#1}:#2}}$\rangle$%
}

\setlength{\fboxsep}{2pt}
\setlength{\abovecaptionskip}{0\baselineskip}
\setlength{\textfloatsep}{\baselineskip}
\setlength{\intextsep}{0.25\baselineskip}
\setlength{\jot}{0\baselineskip}

\mathtoolsset{showmanualtags}
\newtagform{brack}{[}{]}
\Crefformat{equation}{#2Equation~#1#3}
\urlstyle{tt}

\citestyle{acmauthoryear}
\bibliographystyle{ACM-Reference-Format}

\title[]{Commuting Conversions and Join Points \titlebreak for Call-By-Push-Value}

\author{Jonathan Chan}
\orcid{0000-0003-0830-3180}
\affiliation{University of Pennsylvania}
\email{jcxz@seas.upenn.edu}

\author{Madi Gudin}
\affiliation{Amherst College}
\email{mgudin27@amherst.edu}

\author{Annabel Levy}
\affiliation{University of Maryland, Baltimore County}
\email{alevy2@umbc.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{University of Pennsylvania}
\email{sweirich@seas.upenn.edu}

\acmJournal{PACMPL}
\acmConference[short]{name}{date}{venue}
\acmVolume{}
\acmNumber{}
\acmArticle{}
\acmYear{}
\acmMonth{}
\acmISBN{}
\acmDOI{}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011006.10011008.10011009.10011012</concept_id>
       <concept_desc>Software and its engineering~Functional languages</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011008.10011024.10011027</concept_id>
       <concept_desc>Software and its engineering~Control structures</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Functional languages}
\ccsdesc[500]{Software and its engineering~Control structures}

\inputott{rules}

\begin{document}

\setlength{\abovedisplayskip}{0.25\baselineskip}
\setlength{\belowdisplayskip}{0.25\baselineskip}

\begin{abstract}

\end{abstract}

\maketitle

\section{Key Ideas}

The core ideas of this paper begin with the thesis that CBPV \citep{CBPV}
is suitable as a compiler intermediate representation (IR)
because it represents control flow explicitly \citep{CFG}.
In particular, it subsumes both call-by-name (CBN) and call-by-value (CBV) semantics of lambda calculus:
compiling a lambda calculus term with the CBN or CBV compilation strategy yields different CBPV terms
whose execution mirrors that of the original evaluation strategy.

\begin{figure}[h]
  \begin{align}
    [[v]], [[w]] &\dblcolon= [[x]] \mid [[()]] \mid [[inl v]] \mid [[inr v]] \mid [[{m}]] \tag{values} \\
    [[m]], [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[⟨m, m⟩]] \mid [[fst n]] \mid [[snd n]] \mid [[return v]] \tag{computations} \\
    &\mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m1 ; inr y ⇒ m2]] \nonumber
  \end{align}
  \caption{Syntax of call-by-push-value values and computations}
  \Description[]{}
  \label{fig:syntax}
\end{figure}

CBPV syntactically distinguishes values and computations,
using explicit thunks to turn suspended computations into values
and explicit returns to embed values into computations,
which the CBN and CBV translations use in different ways to enforce when computation occurs.
\Cref{fig:syntax} lists the values and computations we work with in this paper,
which consists of the lambda calculus with a unit value, value sums, computation pairs,
along with the CBPV thunk and return constructs.

As an example of the way CBN and CBV translations differ,
consider the lambda calculus term $[[(λx. x) ((λy. y) z)]]$,
which translates to the following two CBPV terms.
%
\begin{align*}
  \textbf{CBN} &\quad [[:concrete: (λx. x!) {(λy. y!) {z!}}]] \\
  \textbf{CBV} &\quad [[:concrete: let f ← return {λx. return x} in let a ← (let g ← return {λy. return y} in g! z) in f! a]]
\end{align*}

While both terms evaluate to the same final value $[[z]]$,
their evaluation sequences are different.
In the CBN translation, function arguments are \{thunked\} and passed wholesale,
then forced$!$ as they are needed.
In the CBV translation, the function and the argument are evaluated in order
before carrying out the function application,
using let bindings to express the explicit sequencing.
First $f$ is evaluated, followed by $g$, then $a$, before the final application occurs.

The distinction between the strategies has implications for performance.
Passing thunks explicitly to functions in CBN may needlessly duplicate code execution
if those arguments are used multiple times.
Conversely, evaluating arguments before passing them to functions in CBV
may needlessly execute code if those arguments are not used at all.
Choosing one evaluation strategy over another is choosing between these tradeoffs,
and CBPV provides a uniform interface for manipulating code once the decision is made
without introducing behaviour that violates the expected strategy.

To seriously consider CBPV as an IR, we need to think about what happens after compiling to CBPV.
At a high level, a compiler IR may undergo some optimization passes,
then compiled to lower-level IRs.
In this paper, we look at passes that affect control flow,
and in particular at commuting conversions.

\subsection{Commuting conversions}

Commuting conversions are syntactic transformations
pushing evaluation contexts into tail positions of eliminators
that preserve evaluation order.
An important benefit of performing commuting conversions is that it exposes inlining opportunities ---
that is, subexpressions that can be reduced to simplify code.
For instance, we can commute a let-bound conditional to reveal direct bindings of returned values.
(We use syntactic sugar for boolean conditionals implemented as sums.)
%
\usetagform{brack}
\begin{align}
  \nonumber
  & [[let b ← (if v then return false else return w) in m]] \\
  \label{eq:let-if}
  \Longrightarrow \ & [[if v then (let b ← return false in m) else (let b ← return w in m)]]
\end{align}
\usetagform{default}

Now we may choose to inline $[[false]]$ inside of $[[m]]$ in place of $[[b]]$
and simplify the then branch.
We may also choose \emph{not} to inline $[[w]]$ in the else branch
if it happens that $[[w]]$ is a particularly large value we don't want to duplicate.
The inlining optimization wouldn't have been possible without the commutation,
and is a well-known technique \citep{join};
this particular commutation is part of \emph{case-floating}.

Following \citet{join}, we extract out from our syntax the evaluation contexts,
which are elimination forms with holes in place of computation scrutinees,
and the tail contexts, which are elimination forms with holes in place of all other computations.
These yield a total of eight commuting conversions,
where four evaluation contexts commute with two tail contexts.
They have straightfoward generalizations to more constructs:
for instance, if we were to add value pairs, which are eliminated by pattern matching,
we would add an additional tail context, producing four more commuting conversions.

\begin{figure}[h]
  \begin{align}
    \tag{evaluation contexts}   [[E]] &\dblcolon= [[let x ← □ in m]] \mid [[□ v]] \mid [[fst □]] \mid [[snd □]] \\
    \tag{tail contexts}         [[L]] &\dblcolon= [[let x ← n in □]] \mid [[case v of inl x ⇒ □ ; inr y ⇒ □]] \\
    \tag{commuting conversions} & [[ E[ L[m] ] ]] \Longrightarrow [[ L[ E[m] ] ]]
  \end{align}
  \caption{Evaluation and tail contexts; commuting conversions}
  \Description[]{}
  \label{fig:commute}
\end{figure}

Another benefit of commuting conversions is that it syntactically sequentializes code,
in the sense that code becomes less nested and more resembles assembly code.
On the right-hand side of \cref{eq:let-if},
we can imagine further compiling the term
into a branching instruction to two code blocks,
each of which assign some value to a register before continuing with the code in $[[m]]$.
This sequentialization is the result of pushing computations into tail positions
in the commuting conversions.

The sequentializing nature of commuting conversions resembles
the A-normalization compiler pass into A-normal form (ANF)
because commuting conversions are in fact the A-reductions that characterize ANF \citep{ANF}.
For the lambda calculus, A-normalization does two things:
it binds intermediate computations,
and it sequentializes computations.
It does the former by including evaluation contexts with holes
in the argument position of function applications
and in the scrutinee position of case expressions.
CBPV doesn't require such contexts since the translation into CBPV
has already either thunked (for CBN) or bound (for CBV) intermediate computations.
All that's left to do is to sequentialize them via commuting conversions.%
\footnote{This is similar to first compiling to monadic normal form (MNF),
which only binds intermediate computations,
then performing sequentialization afterwards \citep{ANF-dead}.}
%
\begin{figure}[h]
  \begin{align}
    [[n]] &\dblcolon= [[v!]] \mid [[λx. m]] \mid [[n v]] \mid [[return v]] \mid [[fst n]] \mid [[snd n]] \tag{computations} \\
    [[m]] &\dblcolon= n \mid [[let x ← n in m]] \mid [[case v of inl x ⇒ m1 ; inr y ⇒ m2]] \tag{configurations}
  \end{align}
  \caption{Commuting conversion normal form of computations and configurations}
  \Description[]{}
  \label{fig:ccnf}
\end{figure}

Rather than performing commuting conversions one by one,
we present a one-pass transformation into a normal form
with respect to all commuting conversions (CCNF) in \cref{sec:ccnf}. % TODO: Is this really the best name?
% \footnote{Compiling with Continuations, Continued also calls them cc-normal form.}
To borrow terminology from ANF,
we call $[[E]]$s that are filled with terms free of $[[L]]$s \emph{computations},
while we call filled $[[L]]$s \emph{configurations},
using $[[n]]$ for such computations only and $[[m]]$ for configurations.
\Cref{fig:ccnf} explicitly lists the syntax obtained from these fillings;
values remain the same, where thunks may contain configurations.

Because the commuting conversions only introduce new computations in tail position,
\emph{new} opportunities for inlining only occur in tail position,
so performing those new inlinings will not violate CCNF.
However, subsequent inlinings that involve forcing direct thunks may violate CCNF.
Consider the following sequence of a commutation followed by an inlining that reduces a function.
%
\begin{align}
  &[[(let x ← n1 in (λy'. let y ← y'! in m1)) {let z ← n2 in m2}]] \nonumber \\
  &\Longrightarrow [[let x ← n1 in ((λy'. let y ← y'! in m1) {let z ← n2 in m2})]] \tag{\textit{commute}} \\
  &\Longrightarrow [[let x ← n1 in (let y ← {let z ← n2 in m2}! in m1)]] \tag{\textit{inline}}
\end{align}

The resulting term is in CCNF, but if we force the thunk,
we end up with a nested let expression, which is not in CCNF.
Therefore, renormalization is required after cascading inlinings that involve forcing thunks.

\subsection{Join points}

There is a glaring code optimization issue with the commuting conversion in \cref{eq:let-if},
and in general with commuting let-bound case expressions:
the let body $[[m]]$ gets duplicated across the branches of the case expression.
%
\usetagform{brack}
\begin{align}
  \nonumber
  &[[let x ← (case v of inl y1 ⇒ m1 ; inr y2 ⇒ m2) in m]] \\
  \label{eq:duped}
  \Longrightarrow \ &[[case v of inl y1 ⇒ (let x ← m1 in m) ; inr y2 ⇒ (let x ← m1 in m)]]
\end{align}
\usetagform{default}

If the size of $[[m]]$ is very large, this can cause code bloat,
especially if the branches contain further case expressions.
The usual solution for the lambda calculus with let expressions
is to let-bind a closure containing $[[m]]$ to be called at the end of the branch,
also known as a \emph{join point}.
Similarly, in CBPV, we can bind a thunked function to be forced and applied.
%
\usetagform{brack}
\begin{align}
  & \nonumber {\color{gray} [[let x ← (case v of inl y1 ⇒ m1 ; inr y2 ⇒ m2) in m]]} \\
  \label{eq:let-join} \Longrightarrow \ &[[let z ← return {λx. m} in _]] \\
  & \nonumber \phantom{\kw{let} \gap}
  [[case v of inl y1 ⇒ (let x ← m1 in z! x) ; inr y2 ⇒ (let x ← m2 in z! x)]]
\end{align}
\usetagform{default}

To the next compiler passes that see this code,
the thunk is a value that may capture variables and escape its scope,
so somewhere along the pipeline, the thunk will be converted into a closure and lifted out,
and $[[z! x]]$ will correspond to a function call.
However, we know from the commuting conversion that the thunk will never escape its scope,
since it's never passed to a function or stored in another thunk;
all that we do to it is force it and apply the function within.
Its purpose is only to join up branches of a computation,
and should be compiled to a local code block that is jumped to.
%
\begin{figure}
  \begin{align}
    m &\dblcolon= \dots \mid [[join j x = m in m]] \mid [[jump j v]]
    \tag{join points, jumps}
  \end{align}
  \caption{Extended configurations}
  \Description[]{}
  \label{fig:join}
\end{figure}

Inspired by \citet{join},
who tackle the same issue with commuting conversion in System F with case expressions,
we too add explicit join point and jump constructs to CBPV in \cref{fig:join}.
They are accompanied by typing rules that restrict where join points may be used,
which we cover in \cref{sec:cbpv}.
In contrast to \opcit,
our jumps are configurations and may only appear in tail position,
as commuting-conversion normalization discards contexts around jumps.
All in all, these restrictions ensure that join points are only ever used by local tail jumps.

Coming back to the commuting conversion of \cref{eq:let-join},
we use join points in place of the bound thunk,
jumping to them after binding the branches.
%
\usetagform{brack}
\begin{align}
  & \nonumber {\color{gray} [[let x ← (case v of inl y1 ⇒ m1 ; inr y2 ⇒ m2) in m]]} \\
  \Longrightarrow \ &[[join j x = m in _]] \\
  & \nonumber \phantom{\kw{join} \gap}
  [[case v of inl y1 ⇒ (let x ← m1 in jump j x) ; inr y2 ⇒ (let x ← m2 in jump j x)]]
\end{align}
\usetagform{default}

Unfortunately, even with join points,
the case-in-case optimizations highlighted in \opcit are not performed,
as the translation to CBPV has already obscured these opportunities.
Case-in-case optimizations deal with case expressions in lambda calculus
whose scrutinees are themselves case expressions,
where a commuting conversion followed by an inlining simplifies away an inner case analysis.
Consider the following example in lambda calculus with conditionals,
where the left-hand side would be optimized with join points to the right-hand side.
%
\usetagform{brack}
\begin{align}
  &[[:concrete: if (if v then false else w) then m_1 else m_2]] \nonumber \\
  \Longrightarrow \ &[[join j = m2 in (if v then jump j else (if w then m1 else jump j))]]
\end{align}
\usetagform{default}

If we translate the left-hand side for both CBN and CBV to CBPV,
the inner conditional is bound in an intermediate let expression,
making its case-in-case nature difficult to identify.%
\footnote{\Citet{ANF-dead} also highlights this difficulty in the context of MNF.}
Further sequentialization (and inlining) with join points prevents duplication of $[[m1]]$ and $[[m2]]$,
but contains an extra conditional inside the join point,
which is unnecessary in the branch where $[[v]]$ is $[[true]]$
and we know the next computation to execute must be $[[m2]]$.
%
\begin{align}
  & {\color{gray} [[:concrete: if (if v then false else w) then m_1 else m_2]]} \nonumber \\
  \Longrightarrow \ & [[let x ← (if v then return false else return w) in (if x then m1 else m2)]] \tag{\textit{CBPV}} \\
  \Longrightarrow \ & [[join j x = (if x then m1 else m2) in _]] \tag{\textit{commute, inline}} \\
  & \phantom{\kw{join} \gap} [[(if v then jump j false else jump j w)]] \nonumber
\end{align}

Even so, join points still successfully solve the problem of preventing
duplication of $[[m1]]$ and $[[m2]]$ without creating a new thunk.

\subsection{Contributions}

\section{CBPV with Join Points} \label{sec:cbpv}

\section{Commuting-Conversion Normalization} \label{sec:ccnf}

\section{Related Work}

\Citet{CBPV-Coq} mechanize in Rocq a vast amount of metatheory for call-by-push-value,
including normalization and observational equivalence.
Our work builds on their design of logical equivalence between terms.
They show a number of commuting conversions as semantic equivalences,
namely commuting let-bound let expressions (Lemma 8.4, Equation 5)
and function application of let expressions (Lemma 8.6, Equation 1),
but are not comprehensive in listing all possible commuting conversions systematically
as we have done in (\TODO: eventually).

Our join points and their typing judgements with a separate join point typing context
are inspired by \citet{join}, who add join points and jumps to System F,
and implement their system in the Haskell compiler GHC.
We simplify the addition by only allowing jumps in tail position,
while they permit jumps in evaluation contexts.
They perform their optimizations equation by equation,
which yields intermediate steps that require this permissiveness,
such as the following.
%
\begin{align*}
  [[(join j x = m in jump j v) w]] &\Longrightarrow [[join j x = m w in (jump j v) w]] \\
                                   &\Longrightarrow [[join j x = m w in jump j v]]
\end{align*}
Because we present instead a single-pass algorithm,
we never produce such intermediate steps that need to be typeable,
so we are able to eliminate them from our syntax outright.
Doing so also simplifies typing:
their jumps need to be typeable with arbitrary types,
which they implement using type polymorphism,
while our jumps are always in tail position
and fixed to the return type of the join point they jump to.

Instead of specialized join and jump constructs,
\citet{wowo} use control operators that bind second-class continuations,
along with a type system that distinguishes between first- and second-class values.
Their system allows for both direct style and continuation-passing style optimizations;
this is not directly applicable to CBPV, which is already in direct style
by virtue of binding intermediate computations.
However, the corresponding dual of CBPV is stack-passing style \citep{compiling},
and it would be interesting to see whether a similar technique could be applied using second-class stacks.

\iffalse
\begin{align}
  [[let x ← (let y ← m1 in m2) in m3]]
  & \Longrightarrow [[let y ← m1 in let x ← m2 in m3]]
  \tag{let--let} \\
  [[(let x ← n in m) v]]
  & \Longrightarrow [[let x ← n in m v]]
  \tag{let--app} \\
  [[fst (let x ← n in m)]]
  & \Longrightarrow [[let x ← n in fst m]]
  \tag{let--fst} \\
  [[snd (let x ← n in m)]]
  & \Longrightarrow [[let x ← n in snd m]]
  \tag{let--snd} \\
  [[let x ← (case v of inl y ⇒ m1 ; inr z ⇒ m2) in m]]
  & \Longrightarrow \nonumber \\
  \mathclap{[[case v of inl y ⇒ let x ← m1 in m ; inr z ⇒ let x ← m2 in m]]}
  \tag{case--let} \\
  [[(case v of inl x ⇒ m1 ; inr y ⇒ m2) w]]
  & \Longrightarrow \nonumber \\
  \mathclap{[[case v of inl x ⇒ m1 w ; inr y ⇒ (# m2 w #)]]}
  \tag{case--app} \\
  [[fst (case v of inl x ⇒ m1 ; inr y ⇒ m2)]]
  & \Longrightarrow \nonumber \\
  \mathclap{[[case v of inl x ⇒ fst m1 ; inr y ⇒ fst m2]]}
  \tag{case--fst} \\
  [[snd (case v of inl x ⇒ m1 ; inr y ⇒ m2)]]
  & \Longrightarrow \nonumber \\
  \mathclap{[[case v of inl x ⇒ snd m1 ; inr y ⇒ snd m2]]}
  \tag{case--snd}
\end{align}
\fi

\bibliography{main}

\end{document}
